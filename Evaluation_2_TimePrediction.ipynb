{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e05cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cb5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline, AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce730898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e69c5b",
   "metadata": {},
   "source": [
    "## Year Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ec9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_from_disk('/datadrive_2/frozen_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6efbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8770b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /datadrive_2/frozen_corpus/test/cache-5b54b43a305c6ec8.arrow\n"
     ]
    }
   ],
   "source": [
    "test_set = test_data['test'].shuffle(seed=42).select(range(10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aca0b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-8078932f57f58a96.arrow\n"
     ]
    }
   ],
   "source": [
    "def mask_time_token(example):\n",
    "    return {'masked': '[MASK] [SEP] '+ example['sentences']}\n",
    "test_set = test_set.map(mask_time_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee2edef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'masked'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4099e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/datadrive_2')\n",
    "checkpoints = ['bnert_time','bnert-time-st-y']\n",
    "model_dict = defaultdict(dict)\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    model_dict[checkpoint]['model'] = AutoModelForMaskedLM.from_pretrained(path / checkpoint)#.to('cuda')\n",
    "    model_dict[checkpoint]['tokenizer'] = AutoTokenizer.from_pretrained(path / checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd19b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_masked_batches(data,batch_size=128):\n",
    "    return (data[i:i+batch_size]['masked'] for i in range(0,len(data), batch_size))\n",
    "\n",
    "def get_year_prediction(data,model,tokenizer,mask_position=1):\n",
    "    predictions = []\n",
    "    batches = get_masked_batches(data)\n",
    "    for batch in tqdm(batches):\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding='max_length', max_length=256, truncation=True,)\n",
    "        outputs = model(**inputs)\n",
    "        #torch.cuda.empty_cache()\n",
    "        predictions.extend([tokenizer.decode(i.item()) for i in outputs.logits[:,mask_position,:].argmax(dim=-1)])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cebaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96bcf1ac96e48ed96eef36c9f73167e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "result_dict = {}\n",
    "for ch in checkpoints:\n",
    "    result_dict[ch] = get_year_prediction(test_set, \n",
    "                                          model_dict[ch]['model'],\n",
    "                                          model_dict[ch]['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9298e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array(test_data['train']['year'])\n",
    "mc_year = Counter(years).most_common(1)[0][0]; mc_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73985532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_baseline(example):\n",
    "    predicted = int(np.random.choice(years, size=1))\n",
    "    target_year = int(example['year'])\n",
    "    return {'diff_random':abs(target_year-predicted)}\n",
    "\n",
    "\n",
    "def majority_baseline(example):\n",
    "    predicted = int(np.random.choice(years, size=1))\n",
    "    return {'diff_majority':abs(1846-predicted)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c444db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.map(random_baseline)\n",
    "test_set = test_set.map(majority_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15f56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_set.remove_columns([ 'pol', 'loc', 'masked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d5faeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f730ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch,res in result_dict.items():\n",
    "    results_df[ch] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24916967",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['diff-time-ts'] = results_df.apply(lambda x: abs(x.year - int(x['bnert-time-st-y'].lstrip('[').rstrip(']'))),\n",
    "                                              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f63ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['diff-time-no-ts'] = results_df.apply(lambda x: abs(x.year - int(x['bnert_time'])),\n",
    "                                              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7c52d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &       0 \\\\\n",
      "\\midrule\n",
      "diff\\_random     &  18.783 \\\\\n",
      "diff\\_majority   &  12.921 \\\\\n",
      "diff-time-ts    &   8.531 \\\\\n",
      "diff-time-no-ts &   7.315 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3359992/959568573.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df[[c for c in results_df.columns if c.startswith('diff')]].mean(axis=0).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(results_df[[c for c in results_df.columns if c.startswith('diff')]].mean(axis=0).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_sent_batches(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3753a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2564c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[0]\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(batch, return_tensors='pt', padding='longest')\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs.logits[:,1,:].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filler('[MASK] [SEP] Her Majesty the Queen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array(test_data['train']['year'])\n",
    "mc_year = Counter(years).most_common(1)[0][0]; mc_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a86ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_set['diff_random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_set['diff_majority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_first_prediction(example):\n",
    "    #try:\n",
    "        text = '[MASK] [MET] ' + example['sentences']\n",
    "        tokenized = tokenizer(text)\n",
    "        if len(tokenized['input_ids']) > 512:\n",
    "            print(len(text))\n",
    "            print(text)\n",
    "            text = tokenizer.decode(tokenized['input_ids'][:500]) + ' [SEP]'\n",
    "            print(text)\n",
    "            print(len(text))\n",
    "        predictions = mask_filler(text)\n",
    "        target_year = int(example['year'])\n",
    "        print(predictions)\n",
    "        pred_year = predictions[0]['token_str'].rstrip(']').lstrip('[')\n",
    "        print(pred_year)\n",
    "        return {'diff':abs(target_year-int(pred_year))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.map(diff_first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a370d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_set.remove_columns(['nlp', 'pol', 'sentences',])\n",
    "data = data.to_pandas()\n",
    "data['diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0014ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diff_majority'] = test_set['diff_majority']\n",
    "data['diff_random'] = test_set['diff_random']\n",
    "data[['diff_majority','diff_random','diff']].plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='year',y='diff',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c02051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data[['year','ocr']]\n",
    "y = data['diff']\n",
    "reg = LinearRegression().fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd888c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(test_set['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mask_filler('[MASK] [SEP] Hello, my Queen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f5771",
   "metadata": {},
   "source": [
    "## Masking Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b32169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Mr. Gladstone might be observed on the ministerial side of thehouse, making every sort of parliamentary endeavour to catch the Speaker's eye.\"\n",
    "\"Mr. Disraeli, however, preserved so much of his prerogtive as the hitherto recognised leader of her Majesty's Opposition as to obtain without difficulty the right of pre-audience.\"\n",
    "\n",
    "\n",
    "sent = \"The Prime Minister, Mr. [MASK] might be observed on the ministerial side of thehouse, making every sort of parliamentary endeavour to catch the Speaker's eye.\"\n",
    "#sent = \"Mr. Peel might be observed on the ministerial side of thehouse, making every sort of parliamentary endeavour to catch the Speaker's eye. Mr. [MASK], however, preserved so much of his prerogtive as the hitherto recognised leader of her Majesty's Opposition as to obtain without difficulty the right of pre-audience.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/datadrive_2/bnert_time\")\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=\"/datadrive_2/bnert_time\", top_k=5, tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"1830 [SEP] {sent}\"\n",
    "#text = '[MASK] [SEP] His Majesty spoke to the people.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854bd72e",
   "metadata": {},
   "source": [
    "## Loading Model and Dataset\n",
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd34e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/datadrive_2/hf_cache/'\n",
    "dataset = load_dataset(\"davanstrien/hmd_newspapers\", cache_dir=cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb37c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'(\\bprime\\sminister\\b)', re.I)\n",
    "#pattern.findall(\"gladstone  d'isreali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3666736",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = dataset.filter(lambda x: len(pattern.findall(x['text'])) > 0 , num_proc=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prm.filter(lambda x: x['date'].year > 1850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(r'(\\bgladstone|\\bisreali\\b)', re.I)\n",
    "prm1 = a.filter(lambda x: len(pattern1.findall(x['text'])) > 0 , num_proc=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm1['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [mask_filler('[MASK] [SEP] '+ text[:900]) for text in prm['train']['text'][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32973b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c510572",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bnert\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0605e0c",
   "metadata": {},
   "source": [
    "## Extracting Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a58180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
