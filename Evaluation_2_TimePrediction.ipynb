{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7cb5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import pipeline, AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e69c5b",
   "metadata": {},
   "source": [
    "## Year Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ec9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_from_disk('/datadrive_2/frozen_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6efbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89d71091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-18daae07a5d7f4c8.arrow\n",
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-573058092beebe7f.arrow\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data.map(lambda examples: {'sentences': [x.lower() for x in examples['sentences']]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8770b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /datadrive_2/frozen_corpus/test/cache-8bc902c778a6e7a6.arrow\n"
     ]
    }
   ],
   "source": [
    "test_set = test_data['test'].shuffle(seed=42).select(range(10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfb261c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-20b4c5659e03f52f.arrow\n"
     ]
    }
   ],
   "source": [
    "masked_year = True\n",
    "if masked_year:\n",
    "    import re\n",
    "    pattern = re.compile(r'\\b1[789][0-9]{2}\\b')\n",
    "    test_set = test_set.map(lambda x: {'sentences': pattern.sub('[MASK]',x['sentences'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f249a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca0b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-882e4f56562607c5.arrow\n",
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-30718c510e8e1f5c.arrow\n"
     ]
    }
   ],
   "source": [
    "def mask_time_token(example,special_token='SEP'):\n",
    "    return {f'masked_{special_token}': f'[MASK] [{special_token}] '+ example['sentences']}\n",
    "test_set = test_set.map(mask_time_token, fn_kwargs={'special_token':'SEP'})\n",
    "test_set = test_set.map(mask_time_token, fn_kwargs={'special_token':'DATE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a0d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [('bnert-time-st-y','/datadrive_2/bnert-time-st-y','SEP'),\n",
    "               ('bnert-time-y','/datadrive_2/bnert-time-y','DATE'),\n",
    "               ('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','DATE'),\n",
    "               ('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','DATE')]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    model_dict[name]['special_token'] = st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8408605a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 1857,\n",
       " 'nlp': 2194,\n",
       " 'pol': '[lib]',\n",
       " 'loc': '[london]',\n",
       " 'sentences': \"to alexandria some daysago, after having successfully performed the objectof her mission, which was undertake', for the pur-pose of taking deep-water soundings between alex-andria, rhodes, and candia. the greatest depthof water on the line to rhodes, i am inf.: ,rmed, wasabout 1,650 fathoms, and on that between alex-andria and candia about 1,700 fathoms. the bot-tom was found to consist generally of yellow mud.the sounding apparatus, i understand, was en-tirely constrected on board.captain mansell, at the'request of the viceroy, isat present engaged in a general survey of the coastsof the red sea, to the distance of some miles oneither side of\",\n",
       " 'ocr': 0.9506,\n",
       " 'length': 100,\n",
       " 'masked_SEP': \"[MASK] [SEP] to alexandria some daysago, after having successfully performed the objectof her mission, which was undertake', for the pur-pose of taking deep-water soundings between alex-andria, rhodes, and candia. the greatest depthof water on the line to rhodes, i am inf.: ,rmed, wasabout 1,650 fathoms, and on that between alex-andria and candia about 1,700 fathoms. the bot-tom was found to consist generally of yellow mud.the sounding apparatus, i understand, was en-tirely constrected on board.captain mansell, at the'request of the viceroy, isat present engaged in a general survey of the coastsof the red sea, to the distance of some miles oneither side of\",\n",
       " 'masked_DATE': \"[MASK] [DATE] to alexandria some daysago, after having successfully performed the objectof her mission, which was undertake', for the pur-pose of taking deep-water soundings between alex-andria, rhodes, and candia. the greatest depthof water on the line to rhodes, i am inf.: ,rmed, wasabout 1,650 fathoms, and on that between alex-andria and candia about 1,700 fathoms. the bot-tom was found to consist generally of yellow mud.the sounding apparatus, i understand, was en-tirely constrected on board.captain mansell, at the'request of the viceroy, isat present engaged in a general survey of the coastsof the red sea, to the distance of some miles oneither side of\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd19b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_masked_batches(data,st,batch_size=128):\n",
    "    return (data[i:i+batch_size][f'masked_{st}'] for i in range(0,len(data), batch_size))\n",
    "\n",
    "def get_year_prediction(data,model,tokenizer,st,mask_position=1):\n",
    "    predictions = []\n",
    "    batches = get_masked_batches(data,st)\n",
    "    for batch in tqdm(batches):\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding='max_length', max_length=256, truncation=True,)\n",
    "        outputs = model(**inputs)\n",
    "        #torch.cuda.empty_cache()\n",
    "        predictions.extend([tokenizer.decode(i.item()) for i in outputs.logits[:,mask_position,:].argmax(dim=-1)])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40cebaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e90fa18246d4a87907c305ac0163ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb67b09006b7401aa0ab2ec2a1efd4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae66b0ab1f7e40cf9602eb08a897651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45ac75929d34d129846c17e3c3e9317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "result_dict = {}\n",
    "for name, mdict in model_dict.items():\n",
    "    result_dict[name] = get_year_prediction(test_set, \n",
    "                                          model_dict[name]['model'],\n",
    "                                          model_dict[name]['tokenizer'],\n",
    "                                          model_dict[name]['special_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9298e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1846"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = np.array(test_data['train']['year'])\n",
    "mc_year = Counter(years).most_common(1)[0][0]; mc_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73985532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_baseline(example):\n",
    "    predicted = int(np.random.choice(years, size=1))\n",
    "    target_year = int(example['year'])\n",
    "    return {'diff_random':abs(target_year-predicted)}\n",
    "\n",
    "\n",
    "def majority_baseline(example):\n",
    "    predicted = int(np.random.choice(years, size=1))\n",
    "    return {'diff_majority':abs(1846-predicted)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48c444db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-84a763a1a21f22e0.arrow\n",
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-a7359a50594cc2e5.arrow\n"
     ]
    }
   ],
   "source": [
    "test_set = test_set.map(random_baseline)\n",
    "test_set = test_set.map(majority_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e15f56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_set.remove_columns([ 'pol', 'loc', 'masked_SEP','masked_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d5faeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f730ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch,res in result_dict.items():\n",
    "    results_df[ch] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac8cee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>nlp</th>\n",
       "      <th>sentences</th>\n",
       "      <th>ocr</th>\n",
       "      <th>length</th>\n",
       "      <th>diff_random</th>\n",
       "      <th>diff_majority</th>\n",
       "      <th>bnert-time-st-y</th>\n",
       "      <th>bnert-time-y</th>\n",
       "      <th>bnert-time-y_masked_25</th>\n",
       "      <th>bnert-time-y_masked_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1857</td>\n",
       "      <td>2194</td>\n",
       "      <td>to alexandria some daysago, after having succe...</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>[1854]</td>\n",
       "      <td>1854</td>\n",
       "      <td>1854</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1808</td>\n",
       "      <td>2194</td>\n",
       "      <td>of thee. coin.plaints.in all cases of recent o...</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>100</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>[1810]</td>\n",
       "      <td>1810</td>\n",
       "      <td>1802</td>\n",
       "      <td>1802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1864</td>\n",
       "      <td>2194</td>\n",
       "      <td>july last,\"his head drooped a little, and ther...</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>[1864]</td>\n",
       "      <td>1864</td>\n",
       "      <td>1864</td>\n",
       "      <td>1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1858</td>\n",
       "      <td>2194</td>\n",
       "      <td>golden grain. the weather has,since our last r...</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>[1846]</td>\n",
       "      <td>1846</td>\n",
       "      <td>1846</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1808</td>\n",
       "      <td>2646</td>\n",
       "      <td>treated him with the utmost attention.4, the c...</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>[1823]</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1842</td>\n",
       "      <td>2194</td>\n",
       "      <td>by the hon. member for roxburghshire against t...</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>[1846]</td>\n",
       "      <td>1846</td>\n",
       "      <td>1846</td>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1803</td>\n",
       "      <td>2194</td>\n",
       "      <td>shock ofan earthquake at christiana, in nqrway...</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>[1820]</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1852</td>\n",
       "      <td>2194</td>\n",
       "      <td>house of datontion.the prisoner:—oh i good hea...</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>[1822]</td>\n",
       "      <td>1822</td>\n",
       "      <td>1820</td>\n",
       "      <td>1857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1861</td>\n",
       "      <td>2194</td>\n",
       "      <td>defendant, mr.clark, and the husband of the la...</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>100</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>[1844]</td>\n",
       "      <td>1844</td>\n",
       "      <td>1844</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1826</td>\n",
       "      <td>2194</td>\n",
       "      <td>yodliern.. the two mugs were sent to ole in.te...</td>\n",
       "      <td>0.7383</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[1804]</td>\n",
       "      <td>1818</td>\n",
       "      <td>1819</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year   nlp                                          sentences     ocr  \\\n",
       "0     1857  2194  to alexandria some daysago, after having succe...  0.9506   \n",
       "1     1808  2194  of thee. coin.plaints.in all cases of recent o...  0.7470   \n",
       "2     1864  2194  july last,\"his head drooped a little, and ther...  0.9392   \n",
       "3     1858  2194  golden grain. the weather has,since our last r...  0.9038   \n",
       "4     1808  2646  treated him with the utmost attention.4, the c...  0.9250   \n",
       "...    ...   ...                                                ...     ...   \n",
       "9995  1842  2194  by the hon. member for roxburghshire against t...  0.9647   \n",
       "9996  1803  2194  shock ofan earthquake at christiana, in nqrway...  0.7931   \n",
       "9997  1852  2194  house of datontion.the prisoner:—oh i good hea...  0.8132   \n",
       "9998  1861  2194  defendant, mr.clark, and the husband of the la...  0.9115   \n",
       "9999  1826  2194  yodliern.. the two mugs were sent to ole in.te...  0.7383   \n",
       "\n",
       "      length  diff_random  diff_majority bnert-time-st-y bnert-time-y  \\\n",
       "0        100           32             24          [1854]         1854   \n",
       "1        100           44             18          [1810]         1810   \n",
       "2        100           22             28          [1864]         1864   \n",
       "3        100           11              2          [1846]         1846   \n",
       "4        100            5             11          [1823]         1823   \n",
       "...      ...          ...            ...             ...          ...   \n",
       "9995     100           12             14          [1846]         1846   \n",
       "9996     100            3             14          [1820]         1823   \n",
       "9997     100            3             16          [1822]         1822   \n",
       "9998     100           49              6          [1844]         1844   \n",
       "9999     100            3              5          [1804]         1818   \n",
       "\n",
       "     bnert-time-y_masked_25 bnert-time-y_masked_75  \n",
       "0                      1854                   1854  \n",
       "1                      1802                   1802  \n",
       "2                      1864                   1864  \n",
       "3                      1846                   1846  \n",
       "4                      1823                   1823  \n",
       "...                     ...                    ...  \n",
       "9995                   1846                   1846  \n",
       "9996                   1823                   1851  \n",
       "9997                   1820                   1857  \n",
       "9998                   1844                   1844  \n",
       "9999                   1819                   1819  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24916967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in results_df.columns:\n",
    "    if c.startswith('bnert'):\n",
    "        results_df[f'diff-{c}'] = results_df.apply(lambda x: abs(x.year - int(x[c].lstrip('[').rstrip(']'))),\n",
    "                                              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56085589",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[[c for c in results_df.columns if c.startswith('diff')]].mean(axis=0).to_csv('tables/year_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e87e2c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &        0 \\\\\n",
      "\\midrule\n",
      "diff\\_random                 &  19.2467 \\\\\n",
      "diff\\_majority               &  13.8074 \\\\\n",
      "diff-bnert-time-st-y        &   9.1536 \\\\\n",
      "diff-bnert-time-y           &   8.4410 \\\\\n",
      "diff-bnert-time-y\\_masked\\_25 &   7.5401 \\\\\n",
      "diff-bnert-time-y\\_masked\\_75 &   6.4239 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_405365/959568573.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df[[c for c in results_df.columns if c.startswith('diff')]].mean(axis=0).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(results_df[[c for c in results_df.columns if c.startswith('diff')]].mean(axis=0).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c4871",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_sent_batches(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3753a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2564c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[0]\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(batch, return_tensors='pt', padding='longest')\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs.logits[:,1,:].argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filler('[MASK] [SEP] Her Majesty the Queen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array(test_data['train']['year'])\n",
    "mc_year = Counter(years).most_common(1)[0][0]; mc_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a86ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_set['diff_random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_set['diff_majority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_first_prediction(example):\n",
    "    #try:\n",
    "        text = '[MASK] [MET] ' + example['sentences']\n",
    "        tokenized = tokenizer(text)\n",
    "        if len(tokenized['input_ids']) > 512:\n",
    "            print(len(text))\n",
    "            print(text)\n",
    "            text = tokenizer.decode(tokenized['input_ids'][:500]) + ' [SEP]'\n",
    "            print(text)\n",
    "            print(len(text))\n",
    "        predictions = mask_filler(text)\n",
    "        target_year = int(example['year'])\n",
    "        print(predictions)\n",
    "        pred_year = predictions[0]['token_str'].rstrip(']').lstrip('[')\n",
    "        print(pred_year)\n",
    "        return {'diff':abs(target_year-int(pred_year))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.map(diff_first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a370d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_set.remove_columns(['nlp', 'pol', 'sentences',])\n",
    "data = data.to_pandas()\n",
    "data['diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0014ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diff_majority'] = test_set['diff_majority']\n",
    "data['diff_random'] = test_set['diff_random']\n",
    "data[['diff_majority','diff_random','diff']].plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='year',y='diff',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c02051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data[['year','ocr']]\n",
    "y = data['diff']\n",
    "reg = LinearRegression().fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd888c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.mean(test_set['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mask_filler('[MASK] [SEP] Hello, my Queen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f5771",
   "metadata": {},
   "source": [
    "## Masking Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b32169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Mr. Gladstone might be observed on the ministerial side of thehouse, making every sort of parliamentary endeavour to catch the Speaker's eye.\"\n",
    "\"Mr. Disraeli, however, preserved so much of his prerogtive as the hitherto recognised leader of her Majesty's Opposition as to obtain without difficulty the right of pre-audience.\"\n",
    "\n",
    "\n",
    "sent = \"The Prime Minister, Mr. [MASK] might be observed on the ministerial side of thehouse, making every sort of parliamentary endeavour to catch the Speaker's eye.\"\n",
    "#sent = \"Mr. Peel might be observed on the ministerial side of thehouse, making every sort of parliamentary endeavour to catch the Speaker's eye. Mr. [MASK], however, preserved so much of his prerogtive as the hitherto recognised leader of her Majesty's Opposition as to obtain without difficulty the right of pre-audience.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/datadrive_2/bnert_time\")\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=\"/datadrive_2/bnert_time\", top_k=5, tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"1830 [SEP] {sent}\"\n",
    "#text = '[MASK] [SEP] His Majesty spoke to the people.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854bd72e",
   "metadata": {},
   "source": [
    "## Loading Model and Dataset\n",
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd34e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/datadrive_2/hf_cache/'\n",
    "dataset = load_dataset(\"davanstrien/hmd_newspapers\", cache_dir=cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb37c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'(\\bprime\\sminister\\b)', re.I)\n",
    "#pattern.findall(\"gladstone  d'isreali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3666736",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = dataset.filter(lambda x: len(pattern.findall(x['text'])) > 0 , num_proc=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prm.filter(lambda x: x['date'].year > 1850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(r'(\\bgladstone|\\bisreali\\b)', re.I)\n",
    "prm1 = a.filter(lambda x: len(pattern1.findall(x['text'])) > 0 , num_proc=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm1['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [mask_filler('[MASK] [SEP] '+ text[:900]) for text in prm['train']['text'][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32973b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c510572",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bnert\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0605e0c",
   "metadata": {},
   "source": [
    "## Extracting Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a58180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
