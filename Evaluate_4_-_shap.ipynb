{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b802a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoModelForMaskedLM, AutoTokenizer, DistilBertForSequenceClassification, AutoConfig\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b9aaf",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050393a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained('/datadrive_2/bnert-time-y').cuda()\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(pytorch_model.bin\").cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/datadrive_2/bnert-time-y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81ffb416",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=0 , top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37debd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.04650492966175079,\n",
       "  'token': 6899,\n",
       "  'token_str': '1863',\n",
       "  'sequence': '1863 her majesty the queen.'},\n",
       " {'score': 0.03965051844716072,\n",
       "  'token': 8933,\n",
       "  'token_str': '1853',\n",
       "  'sequence': '1853 her majesty the queen.'},\n",
       " {'score': 0.03878328204154968,\n",
       "  'token': 8421,\n",
       "  'token_str': '1854',\n",
       "  'sequence': '1854 her majesty the queen.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = preds('[MASK] [DATE] her majesty the queen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a3dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'text':'[MASK] [DATE] her majesty the queen.', 'label':'1847'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f60c58e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[MASK] [DATE] her majesty the queen.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1847\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/explainers/_partition.py:136\u001b[0m, in \u001b[0;36mPartition.__call__\u001b[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, fixed_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, main_effects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m              outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124;03m\"\"\" Explain the output of the model on the given arguments.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/explainers/_explainer.py:266\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args))]\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_args \u001b[38;5;129;01min\u001b[39;00m show_progress(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39margs), num_rows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m explainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent):\n\u001b[0;32m--> 266\u001b[0m     row_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_effects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmain_effects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    271\u001b[0m     output_indices\u001b[38;5;241m.\u001b[39mappend(row_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/explainers/_partition.py:154\u001b[0m, in \u001b[0;36mPartition.explain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown fixed_context value passed (must be 0, 1 or None): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39mfixed_context)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# build a masked version of the model for the current input sample\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m fm \u001b[38;5;241m=\u001b[39m \u001b[43mMaskedModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearize_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# make sure we have the base value and current value outputs\u001b[39;00m\n\u001b[1;32m    157\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fm)\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/utils/_masked_model.py:28\u001b[0m, in \u001b[0;36mMaskedModel.__init__\u001b[0;34m(self, model, masker, link, linearize_link, *args)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# if the masker supports it, save what positions vary from the background\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvariants\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variants \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvariants\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variants_column_sums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variants\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variants_row_inds \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variants[:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variants\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     32\u001b[0m     ]\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/maskers/_text.py:295\u001b[0m, in \u001b[0;36mText.invariants\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvariants\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124;03m\"\"\" The names of the features for each mask position for the given input string.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_s_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     invariants \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenized_s), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_prefix \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/maskers/_text.py:274\u001b[0m, in \u001b[0;36mText._update_s_cache\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_s \u001b[38;5;241m!=\u001b[39m s:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_s \u001b[38;5;241m=\u001b[39m s\n\u001b[0;32m--> 274\u001b[0m     tokens, token_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenized_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(token_ids)\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_segments_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tokens)\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/shap/maskers/_text.py:170\u001b[0m, in \u001b[0;36mText.token_segments\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\" Returns the substrings associated with each token in the given string.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     token_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     offsets \u001b[38;5;241m=\u001b[39m token_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    172\u001b[0m     offsets \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m o \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m o \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m offsets]\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2489\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2492\u001b[0m     )\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2497\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2498\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "shap_values = explainer([{'text':'[MASK] [DATE] her majesty the queen.', 'label':'1847'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab7a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bbe76",
   "metadata": {},
   "source": [
    "#Â Political Leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690337f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /datadrive_2/results_bnert-time-y/checkpoint-3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = AutoConfig.from_pretrained(\"/datadrive_2/bNERT/results_bnert-time-y/checkpoint-3000\")\n",
    "model = DistilBertForSequenceClassification(config=config).cuda()\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(pytorch_model.bin\").cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/datadrive_2/bNERT/results_bnert-time-y/checkpoint-3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51227304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20823997",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/datadrive_2/hf_cache/'\n",
    "dataset = load_from_disk(\"/datadrive_2/HMD_context\")\n",
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1414f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66328281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'][1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa273ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(dataset['text'][1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a955b7f",
   "metadata": {},
   "source": [
    "# Animacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load a BERT sentiment analysis model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/datadrive_2/bnert-bnert-time-y-animacy\").cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/datadrive_2/bnert-bnert-time-y-animacy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b98b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define a prediction function\n",
    "def f(x):\n",
    "    tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=256, truncation=True) for v in x]).cuda()\n",
    "    outputs = model(tv)[0].detach().cpu().numpy()\n",
    "    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
    "    val = sp.special.logit(scores[:,1]) # use one vs rest logit units\n",
    "    return val\n",
    "\n",
    "# build an explainer using a token masker\n",
    "explainer = shap.Explainer(f, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe167ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "animacy_data = load_from_disk('/datadrive_2/animacy_split')\n",
    "animacy_data_viz = animacy_data.remove_columns(['Unnamed: 0', 'Date', 'Sentence', 'SentenceCtxt', 'SentenceId', 'TargetExpression', 'animacy', 'humanness', 'st_year_sep', 'year_sep'])\n",
    "animacy_data_viz = animacy_data_viz.rename_column('year_date','text')\n",
    "animacy_data_viz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc995aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "animacy_data_viz['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer(animacy_data_viz['test'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first sentence's explanation\n",
    "shap.plots.text(shap_values[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values.max(0),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488d192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
