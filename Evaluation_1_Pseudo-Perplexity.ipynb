{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988b4cfe",
   "metadata": {},
   "source": [
    "Code adapted from this [Stack Overflow](\n",
    "https://stackoverflow.com/questions/70464428/how-to-calculate-perplexity-of-a-sentence-using-huggingface-masked-language-mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "65456950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2cdf29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/datadrive_2/frozen_corpus')\n",
    "\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1a2f3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-573058092beebe7f.arrow\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data.map(lambda examples: {'sentences': [x.lower() for x in examples['sentences']]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "31df5277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbb18eec4ff4f0da2f028839024426c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b77732a93a4c41927fa32afdedde4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/96977 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189dcd7269a94e0ea119f5fa5414ebf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff4c16346064c629e4307046ac5b4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bf4bd746da4d73a582598670b5a337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e7d148aa734828bf13c60ad80afeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pred_data(example):\n",
    "    return {'st_year_sep': f'[{example[\"year\"]}]' + ' [SEP] ' + example['sentences'] ,\n",
    "     'year_sep': str(example['year']) + ' [SEP] ' + example['sentences'] ,\n",
    "     'year_date': str(example['year']) + ' [DATE] ' + example['sentences'] \n",
    "        \n",
    "    }\n",
    "    \n",
    "test_data = test_data.map(pred_data , num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cc4743c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.shuffle(seed=42).select(range(2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3575b3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'st_year_sep', 'year_sep', 'year_date'],\n",
       "    num_rows: 2500\n",
       "})"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "495a8455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 1867,\n",
       " 'nlp': 2194,\n",
       " 'pol': '[lib]',\n",
       " 'loc': '[london]',\n",
       " 'sentences': 'articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand',\n",
       " 'ocr': 0.9695,\n",
       " 'length': 100,\n",
       " 'st_year_sep': '[1867] [SEP] articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand',\n",
       " 'year_sep': '1867 [SEP] articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand',\n",
       " 'year_date': '1867 [DATE] articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand'}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3e74e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [#('distilbert','distilbert-base-uncased','[SEP]','year_sep'),\n",
    "               ('hmd_distilbert','/datadrive_2/bnert-hmd','[SEP]','year_sep'),\n",
    "               ('bnert-time-st-y','/datadrive_2/bnert-time-st-y','[SEP]','st_year_sep'),\n",
    "               ('bnert-time-y','/datadrive_2/bnert-time-y','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','[DATE]','year_date')]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st, sent_col in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    #model_dict[name]['special_token'] = st\n",
    "    model_dict[name]['sentences'] = sent_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "bd9d13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_perplexity(example, sent_col, name, model, tokenizer):\n",
    "    tensor_input = tokenizer.encode(example[sent_col], return_tensors='pt',truncation=True, max_length=64)\n",
    "    #print(tensor_input.shape)\n",
    "    #if with_meta:\n",
    "    repeat_input = tensor_input.repeat(tensor_input.size(-1)-4, 1)\n",
    "    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[2:-2]\n",
    "    #else:\n",
    "    #    repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
    "    #    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
    "    masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "    labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "    with torch.inference_mode():\n",
    "        loss = model(masked_input, labels=labels).loss\n",
    "    return {f'loss_{name}':np.exp(loss.item())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6b672126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hmd_distilbert\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dcffa936614cb199d56ca0933dde29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-time-st-y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af9a64e78d94e0aa4eaf6369609fc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-time-y_masked_25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb29533002d4cbaad0a4b07306da9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-time-y_masked_75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6065f62c5f8e40d6b4abab5785b870c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, ndict in model_dict.items():\n",
    "    print(f'Evaluating {name}')\n",
    "    test_data = test_data.map(pseudo_perplexity, \n",
    "                              #num_proc=3,\n",
    "                              fn_kwargs={'sent_col':ndict['sentences'],\n",
    "                                        'name': name,\n",
    "                                        'model':ndict['model'],\n",
    "                                        'tokenizer':ndict['tokenizer']  \n",
    "                                   }\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b49ef60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_data.remove_columns(['nlp','loc','length', 'st_year_sep', 'year_sep', 'year_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e2931a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f0d96177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 9)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9a7e0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['pol'] = results_df.pol.apply(lambda x: x.lstrip('[').rstrip(']'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e996a2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_hmd_distilbert            82337.838676\n",
       "loss_bnert-time-st-y           79230.924210\n",
       "loss_bnert-time-y              78720.447952\n",
       "loss_bnert-time-y_masked_25    77423.510455\n",
       "loss_bnert-time-y_masked_75    77552.556247\n",
       "dtype: float64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[c for c in results_df.columns if c.startswith('loss')]].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "93398549",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('tables/pseudo_perplexity_2500ex_64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "1b07d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['dec'] = results_df.year.apply(lambda x: int(str(x)[:3]+'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c084d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.get_dummies(results_df, columns=['pol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0d7935ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'sentences', 'ocr', 'loss_hmd_distilbert',\n",
       "       'loss_bnert-time-st-y', 'loss_bnert-time-y',\n",
       "       'loss_bnert-time-y_masked_25', 'loss_bnert-time-y_masked_75', 'dec',\n",
       "       'pol_con', 'pol_lib', 'pol_neutr', 'pol_none', 'pol_rad'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263ba10",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "1dfe43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "4402ba04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>tm25</td>       <th>  R-squared:         </th> <td>   0.318</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.317</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   581.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 30 Aug 2022</td> <th>  Prob (F-statistic):</th> <td>6.82e-208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:19:17</td>     <th>  Log-Likelihood:    </th> <td> -13367.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2500</td>      <th>  AIC:               </th> <td>2.674e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2497</td>      <th>  BIC:               </th> <td>2.676e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  103.7773</td> <td>  108.775</td> <td>    0.954</td> <td> 0.340</td> <td> -109.521</td> <td>  317.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ocr</th>       <td> -259.3065</td> <td>    7.824</td> <td>  -33.144</td> <td> 0.000</td> <td> -274.648</td> <td> -243.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dec</th>       <td>    0.0798</td> <td>    0.060</td> <td>    1.330</td> <td> 0.184</td> <td>   -0.038</td> <td>    0.197</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2430.149</td> <th>  Durbin-Watson:     </th>  <td>   1.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>147735.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 4.585</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>39.527</td>  <th>  Cond. No.          </th>  <td>1.97e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.97e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   tm25   R-squared:                       0.318\n",
       "Model:                            OLS   Adj. R-squared:                  0.317\n",
       "Method:                 Least Squares   F-statistic:                     581.0\n",
       "Date:                Tue, 30 Aug 2022   Prob (F-statistic):          6.82e-208\n",
       "Time:                        20:19:17   Log-Likelihood:                -13367.\n",
       "No. Observations:                2500   AIC:                         2.674e+04\n",
       "Df Residuals:                    2497   BIC:                         2.676e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    103.7773    108.775      0.954      0.340    -109.521     317.076\n",
       "ocr         -259.3065      7.824    -33.144      0.000    -274.648    -243.965\n",
       "dec            0.0798      0.060      1.330      0.184      -0.038       0.197\n",
       "==============================================================================\n",
       "Omnibus:                     2430.149   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           147735.521\n",
       "Skew:                           4.585   Prob(JB):                         0.00\n",
       "Kurtosis:                      39.527   Cond. No.                     1.97e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.97e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['tm25'] = results_df[\"loss_bnert-time-y_masked_25\"]\n",
    "mod = smf.ols(formula='tm25 ~ ocr + dec ', data=results_df)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa0d3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_random_mask(model, tokenizer, sentence,meta_pos=None):\n",
    "#     tensor_input = tokenizer.encode(sentence, return_tensors='pt')\n",
    "#     #print(tensor_input)\n",
    "#     repeat_input = torch.clone(tensor_input)\n",
    "#     #print(repeat_input)\n",
    "#     sum_mask,i = 0,0\n",
    "#     while sum_mask == 0:\n",
    "#         mask = torch.tensor(np.random.binomial(1, .15, repeat_input.shape[1]))\n",
    "#         sum_mask = sum(mask)\n",
    "        \n",
    "#     if meta_pos:\n",
    "#         mask[meta_pos] = 0\n",
    "#     masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "#     print(masked_input)\n",
    "#     labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "#     print(labels)\n",
    "#     with torch.inference_mode():\n",
    "#         loss = model(masked_input, labels=labels).loss\n",
    "#     return np.exp(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e25d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=lm_datasets[\"train\"],\n",
    "#     eval_dataset=lm_datasets[\"test\"],\n",
    "#     data_collator=data_collator,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
