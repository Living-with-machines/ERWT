{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce28d2b",
   "metadata": {},
   "source": [
    "Code adapted from this [Stack Overflow](\n",
    "https://stackoverflow.com/questions/70464428/how-to-calculate-perplexity-of-a-sentence-using-huggingface-masked-language-mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c687b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b7f36eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/datadrive_2/frozen_corpus')\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "27e2ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba13b67839844b2191276ac2b1c0c891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/96977 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b6e4303583487bb92e99cb4311a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522af5b7c55b4d888ccafb2b2a5b4f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b8104c30614649bd5780eb17eaebfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc507d7040c34bce996112bc29d9121a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07654a30b784562844c2d13481d5ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pred_data(example):\n",
    "    return {'st_year_sep': f'[{example[\"year\"]}]' + ' [SEP] ' + example['sentences'] ,\n",
    "     'year_sep': str(example['year']) + ' [SEP] ' + example['sentences'] ,\n",
    "     'year_date': str(example['year']) + ' [DATE] ' + example['sentences'] \n",
    "        \n",
    "    }\n",
    "    \n",
    "test_data = test_data.map(pred_data , num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5873e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.shuffle(seed=42).select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8e09aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'st_year_sep', 'year_sep', 'year_date'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2515dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [('distilbert','distilbert-base-uncased','[SEP]','year_sep'),\n",
    "               ('hmd_distilbert','/datadrive_2/bnert-hmd','[SEP]','year_sep'),\n",
    "               ('bnert-time-st-y','/datadrive_2/bnert-time-st-y','[SEP]','st_year_sep'),\n",
    "               ('bnert-time-y','/datadrive_2/bnert-time-y','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','[DATE]','year_date')]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st, sent_col in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    #model_dict[name]['special_token'] = st\n",
    "    model_dict[name]['sentences'] = sent_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "55f9819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_perplexity(example, sent_col, name, model, tokenizer):\n",
    "    tensor_input = tokenizer.encode(example[sent_col], return_tensors='pt',truncation=True, max_length=128)\n",
    "    #print(tensor_input.shape)\n",
    "    #if with_meta:\n",
    "    repeat_input = tensor_input.repeat(tensor_input.size(-1)-4, 1)\n",
    "    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[2:-2]\n",
    "    #else:\n",
    "    #    repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
    "    #    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
    "    masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "    labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "    with torch.inference_mode():\n",
    "        loss = model(masked_input, labels=labels).loss\n",
    "    return {f'loss_{name}':np.exp(loss.item())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480f4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating distilbert\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf890632c004c24987da1d720874d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, ndict in model_dict.items():\n",
    "    print(f'Evaluating {name}')\n",
    "    test_data = test_data.map(pseudo_perplexity, \n",
    "                              #num_proc=3,\n",
    "                              fn_kwargs={'sent_col':ndict['sentences'],\n",
    "                                        'name': name,\n",
    "                                        'model':ndict['model'],\n",
    "                                        'tokenizer':ndict['tokenizer']  \n",
    "                                   }\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f23eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_data.remove_columns(['nlp','loc','length', 'st_year_sep', 'year_sep', 'year_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54709686",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[[c for c in results_df.columns if c.startswith('loss')]].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67e6f3",
   "metadata": {},
   "source": [
    "#Â Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b8d7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_random_mask(model, tokenizer, sentence,meta_pos=None):\n",
    "#     tensor_input = tokenizer.encode(sentence, return_tensors='pt')\n",
    "#     #print(tensor_input)\n",
    "#     repeat_input = torch.clone(tensor_input)\n",
    "#     #print(repeat_input)\n",
    "#     sum_mask,i = 0,0\n",
    "#     while sum_mask == 0:\n",
    "#         mask = torch.tensor(np.random.binomial(1, .15, repeat_input.shape[1]))\n",
    "#         sum_mask = sum(mask)\n",
    "        \n",
    "#     if meta_pos:\n",
    "#         mask[meta_pos] = 0\n",
    "#     masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "#     print(masked_input)\n",
    "#     labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "#     print(labels)\n",
    "#     with torch.inference_mode():\n",
    "#         loss = model(masked_input, labels=labels).loss\n",
    "#     return np.exp(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=lm_datasets[\"train\"],\n",
    "#     eval_dataset=lm_datasets[\"test\"],\n",
    "#     data_collator=data_collator,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
