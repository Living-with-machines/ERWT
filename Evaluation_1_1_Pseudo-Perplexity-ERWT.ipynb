{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "65456950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2cdf29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/datadrive_2/frozen_corpus')\n",
    "\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1a2f3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-573058092beebe7f.arrow\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data.map(lambda examples: {'sentences': [x.lower() for x in examples['sentences']]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "31df5277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbb18eec4ff4f0da2f028839024426c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b77732a93a4c41927fa32afdedde4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/96977 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189dcd7269a94e0ea119f5fa5414ebf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff4c16346064c629e4307046ac5b4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bf4bd746da4d73a582598670b5a337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e7d148aa734828bf13c60ad80afeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/96976 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pred_data(example):\n",
    "    return {'st_year_sep': f'[{example[\"year\"]}]' + ' [SEP] ' + example['sentences'] ,\n",
    "     'year_sep': str(example['year']) + ' [SEP] ' + example['sentences'] ,\n",
    "     'year_date': str(example['year']) + ' [DATE] ' + example['sentences'] \n",
    "        \n",
    "    }\n",
    "    \n",
    "test_data = test_data.map(pred_data , num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "cc4743c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.shuffle(seed=42).select(range(2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3575b3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'st_year_sep', 'year_sep', 'year_date'],\n",
       "    num_rows: 2500\n",
       "})"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "495a8455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 1867,\n",
       " 'nlp': 2194,\n",
       " 'pol': '[lib]',\n",
       " 'loc': '[london]',\n",
       " 'sentences': 'articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand',\n",
       " 'ocr': 0.9695,\n",
       " 'length': 100,\n",
       " 'st_year_sep': '[1867] [SEP] articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand',\n",
       " 'year_sep': '1867 [SEP] articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand',\n",
       " 'year_date': '1867 [DATE] articlesbelonging to his employers. in answer to the pre-sident of the court before which he has just beentried as to what was his motive for committing therobbery, the prisoner said \" nothing else butgormandism.\" in truth, the search of his lodgingswent far to prove the truth of his assertion, for thepolice found there chocolate, sardines, figs, pre-serves, and other good eatables belonging to hismasters, and also a box of excellent cigars, whichwould afford a pleasant smoke after a relish. it wasevident also that the prisoner was delicate in his habitsand did not eat with his fingers, for plenty of forksand'}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "3e74e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [#('distilbert','distilbert-base-uncased','[SEP]','year_sep'),\n",
    "               ('hmd_distilbert','/datadrive_2/bnert-hmd','[SEP]','year_sep'),\n",
    "               ('bnert-time-st-y','/datadrive_2/bnert-time-st-y','[SEP]','st_year_sep'),\n",
    "               ('bnert-time-y','/datadrive_2/bnert-time-y','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','[DATE]','year_date')]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st, sent_col in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    #model_dict[name]['special_token'] = st\n",
    "    model_dict[name]['sentences'] = sent_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b4cfe",
   "metadata": {},
   "source": [
    "Code adapted from this [Stack Overflow](\n",
    "https://stackoverflow.com/questions/70464428/how-to-calculate-perplexity-of-a-sentence-using-huggingface-masked-language-mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "bd9d13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_perplexity(example, sent_col, name, model, tokenizer):\n",
    "    tensor_input = tokenizer.encode(example[sent_col], return_tensors='pt',truncation=True, max_length=64)\n",
    "    #print(tensor_input.shape)\n",
    "    #if with_meta:\n",
    "    repeat_input = tensor_input.repeat(tensor_input.size(-1)-4, 1)\n",
    "    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[2:-2]\n",
    "    #else:\n",
    "    #    repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
    "    #    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
    "    masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "    labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "    with torch.inference_mode():\n",
    "        loss = model(masked_input, labels=labels).loss\n",
    "    return {f'loss_{name}':np.exp(loss.item())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6b672126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating hmd_distilbert\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dcffa936614cb199d56ca0933dde29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-time-st-y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af9a64e78d94e0aa4eaf6369609fc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-time-y_masked_25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb29533002d4cbaad0a4b07306da9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-time-y_masked_75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6065f62c5f8e40d6b4abab5785b870c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, ndict in model_dict.items():\n",
    "    print(f'Evaluating {name}')\n",
    "    test_data = test_data.map(pseudo_perplexity, \n",
    "                              #num_proc=3,\n",
    "                              fn_kwargs={'sent_col':ndict['sentences'],\n",
    "                                        'name': name,\n",
    "                                        'model':ndict['model'],\n",
    "                                        'tokenizer':ndict['tokenizer']  \n",
    "                                   }\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b49ef60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_data.remove_columns(['nlp','loc','length', 'st_year_sep', 'year_sep', 'year_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e2931a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f0d96177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 9)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9a7e0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['pol'] = results_df.pol.apply(lambda x: x.lstrip('[').rstrip(']'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e996a2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_hmd_distilbert            82337.838676\n",
       "loss_bnert-time-st-y           79230.924210\n",
       "loss_bnert-time-y              78720.447952\n",
       "loss_bnert-time-y_masked_25    77423.510455\n",
       "loss_bnert-time-y_masked_75    77552.556247\n",
       "dtype: float64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[c for c in results_df.columns if c.startswith('loss')]].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "93398549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.to_csv('tables/pseudo_perplexity_2500ex_64.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f97da7",
   "metadata": {},
   "source": [
    "# Inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "51a7a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classsify_pol_regex\t  pseudo_perplexity_1000ex_l28.csv  year_pred.csv\r\n",
      "classsify_pol_with_regex  pseudo_perplexity_2500ex_64.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "73af72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_128 = pd.read_csv('tables/pseudo_perplexity_1000ex_l28.csv')\n",
    "results_df_64 = pd.read_csv('tables/pseudo_perplexity_2500ex_64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "1e493a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_bnert-time-st-y 5.25563047271443e-58\n",
      "loss_bnert-time-y 1.1377695846624123e-59\n",
      "loss_bnert-time-y_masked_25 1.8018287277557794e-75\n",
      "loss_bnert-time-y_masked_75 2.3685196297043552e-70\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "for ch in ['loss_bnert-time-st-y', 'loss_bnert-time-y', 'loss_bnert-time-y_masked_25', 'loss_bnert-time-y_masked_75']:\n",
    "\n",
    "    print(ch,ttest_rel(results_df_64['loss_hmd_distilbert'],results_df_64[ch], alternative='two-sided').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "90ea182f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_bnert-time-st-y 3.1043206608581707e-33\n",
      "loss_bnert-time-y 1.1046352626321596e-32\n",
      "loss_bnert-time-y_masked_25 6.3127868900169796e-46\n",
      "loss_bnert-time-y_masked_75 3.643521000007317e-43\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "for ch in ['loss_bnert-time-st-y', 'loss_bnert-time-y', 'loss_bnert-time-y_masked_25', 'loss_bnert-time-y_masked_75']:\n",
    "\n",
    "    print(ch,ttest_rel(results_df_128['loss_hmd_distilbert'],results_df_128[ch], alternative='two-sided').pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1b07d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_64['dec'] = results_df_64.year.apply(lambda x: int(str(x)[:3]+'0'))\n",
    "results_df_128['dec'] = results_df_128.year.apply(lambda x: int(str(x)[:3]+'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "66345642",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_64_m = results_df_64[[c for c in results_df_64.columns if c.startswith('loss')]].mean(axis=0) \n",
    "scores_64_sd = results_df_64[[c for c in results_df_64.columns if c.startswith('loss')]].std(axis=0) \n",
    "scores_128_m = results_df_128[[c for c in results_df_128.columns if c.startswith('loss')]].mean(axis=0) \n",
    "scores_128_sd = results_df_128[[c for c in results_df_128.columns if c.startswith('loss')]].std(axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "2001d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &      0 &      1 &       2 &       3 \\\\\n",
      "\\midrule\n",
      "loss\\_hmd\\_distilbert         &  32.94 &  64.78 &   25.72 &   45.99 \\\\\n",
      "loss\\_bnert-time-st-y        &  31.69 &  62.42 &   25.03 &   44.74 \\\\\n",
      "loss\\_bnert-time-y           &  31.49 &  61.85 &   24.97 &   44.58 \\\\\n",
      "loss\\_bnert-time-y\\_masked\\_25 &  30.97 &  61.50 &   24.59 &   44.36 \\\\\n",
      "loss\\_bnert-time-y\\_masked\\_75 &  31.02 &  61.41 &   24.63 &   44.40 \\\\\n",
      "loss\\_distilbert             &    NaN &    NaN &  229.19 &  294.70 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_238407/2314729261.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(pd.concat([scores_64_m,scores_64_sd,scores_128_m,scores_128_sd],axis=1).round(2).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([scores_64_m,scores_64_sd,scores_128_m,scores_128_sd],axis=1).round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "768b1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "c084d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df_64 = pd.get_dummies(results_df_64, columns=['pol'])\n",
    "#results_df_64 = pd.get_dummies(results_df_64, columns=['dec'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "fce00731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>sentences</th>\n",
       "      <th>ocr</th>\n",
       "      <th>loss_hmd_distilbert</th>\n",
       "      <th>loss_bnert-time-st-y</th>\n",
       "      <th>loss_bnert-time-y</th>\n",
       "      <th>loss_bnert-time-y_masked_25</th>\n",
       "      <th>loss_bnert-time-y_masked_75</th>\n",
       "      <th>dec</th>\n",
       "      <th>pol_con</th>\n",
       "      <th>pol_lib</th>\n",
       "      <th>pol_neutr</th>\n",
       "      <th>pol_none</th>\n",
       "      <th>pol_rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1867</td>\n",
       "      <td>articlesbelonging to his employers. in answer ...</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>4.898188</td>\n",
       "      <td>4.800630</td>\n",
       "      <td>4.788208</td>\n",
       "      <td>5.310736</td>\n",
       "      <td>5.341368</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1835</td>\n",
       "      <td>this presump-tion is that the best-informed pe...</td>\n",
       "      <td>0.8501</td>\n",
       "      <td>17.783268</td>\n",
       "      <td>17.446070</td>\n",
       "      <td>17.904489</td>\n",
       "      <td>17.870082</td>\n",
       "      <td>17.897144</td>\n",
       "      <td>1830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1855</td>\n",
       "      <td>courts and of the interference of therussian g...</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>8.072949</td>\n",
       "      <td>7.096237</td>\n",
       "      <td>7.065630</td>\n",
       "      <td>6.701583</td>\n",
       "      <td>6.755984</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1863</td>\n",
       "      <td>french ambassador has been appealed to as toth...</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>8.388589</td>\n",
       "      <td>7.888847</td>\n",
       "      <td>7.970569</td>\n",
       "      <td>8.280886</td>\n",
       "      <td>8.254443</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1828</td>\n",
       "      <td>the red barn en the19th april last, in the fro...</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>11.523887</td>\n",
       "      <td>11.071895</td>\n",
       "      <td>10.978597</td>\n",
       "      <td>10.261653</td>\n",
       "      <td>10.176397</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>1841</td>\n",
       "      <td>that speech was given toman to enable him to d...</td>\n",
       "      <td>0.9318</td>\n",
       "      <td>8.038355</td>\n",
       "      <td>8.212081</td>\n",
       "      <td>8.155450</td>\n",
       "      <td>7.521363</td>\n",
       "      <td>7.530116</td>\n",
       "      <td>1840</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>1838</td>\n",
       "      <td>liverp.ooi, bououg-11 bank,71111(1) dividendr~...</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>78.923141</td>\n",
       "      <td>77.794717</td>\n",
       "      <td>77.626486</td>\n",
       "      <td>72.519289</td>\n",
       "      <td>73.030444</td>\n",
       "      <td>1830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>1819</td>\n",
       "      <td>to. do-the sane,rather than,submit to he depti...</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>28.940866</td>\n",
       "      <td>25.827229</td>\n",
       "      <td>24.760396</td>\n",
       "      <td>24.603723</td>\n",
       "      <td>24.499845</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>1821</td>\n",
       "      <td>- . i imr. fraser's 'mountebank - - . 2 2three...</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>8.221178</td>\n",
       "      <td>8.351394</td>\n",
       "      <td>8.353206</td>\n",
       "      <td>7.691212</td>\n",
       "      <td>7.642458</td>\n",
       "      <td>1820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>1860</td>\n",
       "      <td>traffic return&amp;ilatlwats. non par mar. total. ...</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>80.975870</td>\n",
       "      <td>83.746027</td>\n",
       "      <td>78.749954</td>\n",
       "      <td>82.204043</td>\n",
       "      <td>82.961681</td>\n",
       "      <td>1860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  year  ... pol_none  pol_rad\n",
       "0              0  1867  ...        0        0\n",
       "1              1  1835  ...        0        0\n",
       "2              2  1855  ...        0        0\n",
       "3              3  1863  ...        0        0\n",
       "4              4  1828  ...        0        0\n",
       "...          ...   ...  ...      ...      ...\n",
       "2495        2495  1841  ...        0        0\n",
       "2496        2496  1838  ...        0        0\n",
       "2497        2497  1819  ...        0        0\n",
       "2498        2498  1821  ...        1        0\n",
       "2499        2499  1860  ...        0        0\n",
       "\n",
       "[2500 rows x 15 columns]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "feeca1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_64['HMDist'] = results_df_64[\"loss_hmd_distilbert\"]\n",
    "\n",
    "results_df_64['ERWT'] =  results_df_64[\"loss_bnert-time-y\"]\n",
    "results_df_64['ERWT_ts'] =  results_df_64[\"loss_bnert-time-st-y\"]\n",
    "results_df_64['ERWT_masked_25'] =  results_df_64[\"loss_bnert-time-y_masked_25\"]\n",
    "results_df_64['ERWT_masked_75'] = results_df_64[\"loss_bnert-time-y_masked_75\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "4402ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for m in ['HMDist','ERWT','ERWT_ts','ERWT_masked_25','ERWT_masked_75']:\n",
    "    mod = smf.ols(formula=f'{m} ~ ocr + C(dec) + pol_con + pol_lib + pol_neutr + pol_none + pol_rad', data=results_df_64)\n",
    "    results_dict[m] = mod.fit()\n",
    "#res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "a4d0b882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>ERWT_masked_25</td>  <th>  R-squared:         </th> <td>   0.326</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.323</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   100.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Aug 2022</td> <th>  Prob (F-statistic):</th> <td>5.82e-203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:49:32</td>     <th>  Log-Likelihood:    </th> <td> -13351.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2500</td>      <th>  AIC:               </th> <td>2.673e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2487</td>      <th>  BIC:               </th> <td>2.680e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>  198.4227</td> <td>    6.533</td> <td>   30.371</td> <td> 0.000</td> <td>  185.612</td> <td>  211.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1810]</th> <td>    6.3610</td> <td>    6.001</td> <td>    1.060</td> <td> 0.289</td> <td>   -5.406</td> <td>   18.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1820]</th> <td>   -6.4619</td> <td>    5.560</td> <td>   -1.162</td> <td> 0.245</td> <td>  -17.365</td> <td>    4.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1830]</th> <td>    7.8886</td> <td>    5.961</td> <td>    1.323</td> <td> 0.186</td> <td>   -3.801</td> <td>   19.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1840]</th> <td>    8.1919</td> <td>    5.453</td> <td>    1.502</td> <td> 0.133</td> <td>   -2.500</td> <td>   18.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1850]</th> <td>   13.0512</td> <td>    5.352</td> <td>    2.438</td> <td> 0.015</td> <td>    2.556</td> <td>   23.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1860]</th> <td>   12.2913</td> <td>    5.508</td> <td>    2.232</td> <td> 0.026</td> <td>    1.491</td> <td>   23.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dec)[T.1870]</th> <td>    2.7508</td> <td>   16.069</td> <td>    0.171</td> <td> 0.864</td> <td>  -28.758</td> <td>   34.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ocr</th>            <td> -250.5163</td> <td>    8.390</td> <td>  -29.860</td> <td> 0.000</td> <td> -266.968</td> <td> -234.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_con</th>        <td>   35.5257</td> <td>    3.650</td> <td>    9.734</td> <td> 0.000</td> <td>   28.369</td> <td>   42.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_lib</th>        <td>   34.6409</td> <td>    2.556</td> <td>   13.553</td> <td> 0.000</td> <td>   29.629</td> <td>   39.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_neutr</th>      <td>   23.9520</td> <td>    5.558</td> <td>    4.310</td> <td> 0.000</td> <td>   13.054</td> <td>   34.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_none</th>       <td>   48.4267</td> <td>    3.688</td> <td>   13.132</td> <td> 0.000</td> <td>   41.195</td> <td>   55.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_rad</th>        <td>   55.8774</td> <td>    5.125</td> <td>   10.903</td> <td> 0.000</td> <td>   45.828</td> <td>   65.927</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2435.444</td> <th>  Durbin-Watson:     </th>  <td>   1.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>150665.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 4.594</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>39.905</td>  <th>  Cond. No.          </th>  <td>1.73e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.1e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         ERWT_masked_25   R-squared:                       0.326\n",
       "Model:                            OLS   Adj. R-squared:                  0.323\n",
       "Method:                 Least Squares   F-statistic:                     100.3\n",
       "Date:                Wed, 31 Aug 2022   Prob (F-statistic):          5.82e-203\n",
       "Time:                        16:49:32   Log-Likelihood:                -13351.\n",
       "No. Observations:                2500   AIC:                         2.673e+04\n",
       "Df Residuals:                    2487   BIC:                         2.680e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept        198.4227      6.533     30.371      0.000     185.612     211.234\n",
       "C(dec)[T.1810]     6.3610      6.001      1.060      0.289      -5.406      18.128\n",
       "C(dec)[T.1820]    -6.4619      5.560     -1.162      0.245     -17.365       4.441\n",
       "C(dec)[T.1830]     7.8886      5.961      1.323      0.186      -3.801      19.578\n",
       "C(dec)[T.1840]     8.1919      5.453      1.502      0.133      -2.500      18.884\n",
       "C(dec)[T.1850]    13.0512      5.352      2.438      0.015       2.556      23.547\n",
       "C(dec)[T.1860]    12.2913      5.508      2.232      0.026       1.491      23.092\n",
       "C(dec)[T.1870]     2.7508     16.069      0.171      0.864     -28.758      34.260\n",
       "ocr             -250.5163      8.390    -29.860      0.000    -266.968    -234.065\n",
       "pol_con           35.5257      3.650      9.734      0.000      28.369      42.682\n",
       "pol_lib           34.6409      2.556     13.553      0.000      29.629      39.653\n",
       "pol_neutr         23.9520      5.558      4.310      0.000      13.054      34.850\n",
       "pol_none          48.4267      3.688     13.132      0.000      41.195      55.658\n",
       "pol_rad           55.8774      5.125     10.903      0.000      45.828      65.927\n",
       "==============================================================================\n",
       "Omnibus:                     2435.444   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           150665.128\n",
       "Skew:                           4.594   Prob(JB):                         0.00\n",
       "Kurtosis:                      39.905   Cond. No.                     1.73e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.1e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['ERWT_masked_25'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "ccadcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_params = defaultdict(lambda: defaultdict(dict))\n",
    "models = ['HMDist','ERWT','ERWT_ts','ERWT_masked_25','ERWT_masked_75']\n",
    "parameters =  ['ocr','pol_rad','pol_con','pol_lib','C(dec)[T.1820]','C(dec)[T.1860]']\n",
    "for param in parameters:\n",
    "    for m in models:\n",
    "        result_params[param][m]['coef'] = results_dict[m].params[param]\n",
    "        result_params[param][m]['pvalue'] = results_dict[m].pvalues[param]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "68d75c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "               &                &     coef &  pvalue \\\\\n",
      "\\midrule\n",
      "ocr & HMDist & -264.930 &   0.000 \\\\\n",
      "               & ERWT & -253.228 &   0.000 \\\\\n",
      "               & ERWT\\_ts & -255.035 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_25 & -250.516 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_75 & -250.432 &   0.000 \\\\\n",
      "pol\\_rad & HMDist &   60.481 &   0.000 \\\\\n",
      "               & ERWT &   56.519 &   0.000 \\\\\n",
      "               & ERWT\\_ts &   57.072 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_25 &   55.877 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_75 &   55.967 &   0.000 \\\\\n",
      "pol\\_con & HMDist &   37.560 &   0.000 \\\\\n",
      "               & ERWT &   36.074 &   0.000 \\\\\n",
      "               & ERWT\\_ts &   36.397 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_25 &   35.526 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_75 &   35.573 &   0.000 \\\\\n",
      "pol\\_lib & HMDist &   36.718 &   0.000 \\\\\n",
      "               & ERWT &   35.115 &   0.000 \\\\\n",
      "               & ERWT\\_ts &   35.461 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_25 &   34.641 &   0.000 \\\\\n",
      "               & ERWT\\_masked\\_75 &   34.694 &   0.000 \\\\\n",
      "C(dec)[T.1820] & HMDist &   -8.950 &   0.125 \\\\\n",
      "               & ERWT &   -6.989 &   0.210 \\\\\n",
      "               & ERWT\\_ts &   -7.462 &   0.186 \\\\\n",
      "               & ERWT\\_masked\\_25 &   -6.462 &   0.245 \\\\\n",
      "               & ERWT\\_masked\\_75 &   -6.602 &   0.234 \\\\\n",
      "C(dec)[T.1860] & HMDist &   10.780 &   0.062 \\\\\n",
      "               & ERWT &   12.088 &   0.029 \\\\\n",
      "               & ERWT\\_ts &   11.750 &   0.035 \\\\\n",
      "               & ERWT\\_masked\\_25 &   12.291 &   0.026 \\\\\n",
      "               & ERWT\\_masked\\_75 &   11.990 &   0.029 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_238407/2568293766.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(pd.DataFrame.from_dict({(i,j): result_params[i][j]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict({(i,j): result_params[i][j] \n",
    "                           for i in result_params.keys() \n",
    "                           for j in result_params[i].keys()},\n",
    "                       orient='index').round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "e623273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr</th>\n",
       "      <th>pol_rad</th>\n",
       "      <th>pol_con</th>\n",
       "      <th>pol_lib</th>\n",
       "      <th>C(dec)[T.1820]</th>\n",
       "      <th>C(dec)[T.1860]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HMDist</th>\n",
       "      <td>{'coef': -264.9304633814721, 'pvalue': 2.69425...</td>\n",
       "      <td>{'coef': 60.481497010260675, 'pvalue': 1.00640...</td>\n",
       "      <td>{'coef': 37.56034248820701, 'pvalue': 2.333657...</td>\n",
       "      <td>{'coef': 36.718010165844056, 'pvalue': 2.79981...</td>\n",
       "      <td>{'coef': -8.950011068940016, 'pvalue': 0.12468...</td>\n",
       "      <td>{'coef': 10.779858435283511, 'pvalue': 0.06195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERWT</th>\n",
       "      <td>{'coef': -253.2280442205187, 'pvalue': 7.58729...</td>\n",
       "      <td>{'coef': 56.519271918572514, 'pvalue': 1.77252...</td>\n",
       "      <td>{'coef': 36.07356089334188, 'pvalue': 1.721910...</td>\n",
       "      <td>{'coef': 35.11462232936252, 'pvalue': 3.354089...</td>\n",
       "      <td>{'coef': -6.989408159321629, 'pvalue': 0.21035...</td>\n",
       "      <td>{'coef': 12.087611977577792, 'pvalue': 0.02880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERWT_ts</th>\n",
       "      <td>{'coef': -255.0354294796855, 'pvalue': 5.51766...</td>\n",
       "      <td>{'coef': 57.07181561660919, 'pvalue': 1.851739...</td>\n",
       "      <td>{'coef': 36.39720693279429, 'pvalue': 1.923284...</td>\n",
       "      <td>{'coef': 35.460952114021865, 'pvalue': 3.52937...</td>\n",
       "      <td>{'coef': -7.462268080375932, 'pvalue': 0.18554...</td>\n",
       "      <td>{'coef': 11.750064543099004, 'pvalue': 0.03539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERWT_masked_25</th>\n",
       "      <td>{'coef': -250.5162758760136, 'pvalue': 1.07386...</td>\n",
       "      <td>{'coef': 55.877409148982444, 'pvalue': 4.53580...</td>\n",
       "      <td>{'coef': 35.52573370569881, 'pvalue': 5.290524...</td>\n",
       "      <td>{'coef': 34.64087115161699, 'pvalue': 2.009872...</td>\n",
       "      <td>{'coef': -6.461899323798286, 'pvalue': 0.24528...</td>\n",
       "      <td>{'coef': 12.291269024421709, 'pvalue': 0.02573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERWT_masked_75</th>\n",
       "      <td>{'coef': -250.43203601560785, 'pvalue': 3.0030...</td>\n",
       "      <td>{'coef': 55.96749136824222, 'pvalue': 2.904112...</td>\n",
       "      <td>{'coef': 35.57252590092868, 'pvalue': 3.795387...</td>\n",
       "      <td>{'coef': 34.69364309073651, 'pvalue': 1.044108...</td>\n",
       "      <td>{'coef': -6.602182456272839, 'pvalue': 0.23412...</td>\n",
       "      <td>{'coef': 11.990160385421131, 'pvalue': 0.02921...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              ocr  ...                                     C(dec)[T.1860]\n",
       "HMDist          {'coef': -264.9304633814721, 'pvalue': 2.69425...  ...  {'coef': 10.779858435283511, 'pvalue': 0.06195...\n",
       "ERWT            {'coef': -253.2280442205187, 'pvalue': 7.58729...  ...  {'coef': 12.087611977577792, 'pvalue': 0.02880...\n",
       "ERWT_ts         {'coef': -255.0354294796855, 'pvalue': 5.51766...  ...  {'coef': 11.750064543099004, 'pvalue': 0.03539...\n",
       "ERWT_masked_25  {'coef': -250.5162758760136, 'pvalue': 1.07386...  ...  {'coef': 12.291269024421709, 'pvalue': 0.02573...\n",
       "ERWT_masked_75  {'coef': -250.43203601560785, 'pvalue': 3.0030...  ...  {'coef': 11.990160385421131, 'pvalue': 0.02921...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "2ff33341",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for p in parameters:\n",
    "    cols.extend([f'coef_{p}',f'pvalue_{p}'])\n",
    "\n",
    "#pd.DataFrame.from_dict(result_params, orient='index',columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f5d66a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(result_params['ocr'], index= models).plot(kind='bar',ylim=(-200,-270))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263ba10",
   "metadata": {},
   "source": [
    "#Â Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa0d3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_random_mask(model, tokenizer, sentence,meta_pos=None):\n",
    "#     tensor_input = tokenizer.encode(sentence, return_tensors='pt')\n",
    "#     #print(tensor_input)\n",
    "#     repeat_input = torch.clone(tensor_input)\n",
    "#     #print(repeat_input)\n",
    "#     sum_mask,i = 0,0\n",
    "#     while sum_mask == 0:\n",
    "#         mask = torch.tensor(np.random.binomial(1, .15, repeat_input.shape[1]))\n",
    "#         sum_mask = sum(mask)\n",
    "        \n",
    "#     if meta_pos:\n",
    "#         mask[meta_pos] = 0\n",
    "#     masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "#     print(masked_input)\n",
    "#     labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "#     print(labels)\n",
    "#     with torch.inference_mode():\n",
    "#         loss = model(masked_input, labels=labels).loss\n",
    "#     return np.exp(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e25d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=lm_datasets[\"train\"],\n",
    "#     eval_dataset=lm_datasets[\"test\"],\n",
    "#     data_collator=data_collator,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
