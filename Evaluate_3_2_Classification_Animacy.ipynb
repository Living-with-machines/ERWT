{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import evaluate\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import DataCollatorWithPadding\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78403389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('../animacy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b95a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"../LwM-nlp-animacy-annotations-machines19thC.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563783c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2d9d6",
   "metadata": {},
   "source": [
    "##Â Classify Animacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1babf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_data(example,add_field='Date'):\n",
    "    return {'st_year_sep': f'[{example[add_field]}]' + ' [SEP] ' + example['Sentence'] ,\n",
    "     'year_sep': str(example[add_field]) + ' [SEP] ' + example['Sentence'] ,\n",
    "     'year_date': str(example[add_field]) + ' [DATE] ' + example['Sentence'] \n",
    "        \n",
    "    }\n",
    "    \n",
    "dataset = dataset.map(pred_data , num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ce51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['st_year_sep'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb333c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2code = {label:i for i,label in enumerate(dataset.unique('animacy'))}\n",
    "num_labels = len(lab2code)\n",
    "dataset = dataset.map(lambda x: {'label': lab2code[x['animacy']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d278a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61254c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(len(dataset)*.3)\n",
    "train_test = dataset.train_test_split(test_size=test_size , seed=42)\n",
    "test_set = train_test['test']\n",
    "val_size = int(len(train_test['train'])*.05)\n",
    "train_val =  train_test['train'].train_test_split(test_size=val_size,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.save_to_disk('/datadrive_2/animacy_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348eace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoints = [('distilbert','distilbert-base-uncased','[SEP]','year_sep'),\n",
    "               ('hmd_distilbert','/datadrive_2/bnert-hmd','[SEP]','year_sep'),\n",
    "               ('bnert-time-st-y','/datadrive_2/bnert-time-st-y','[SEP]','st_year_sep'),\n",
    "               ('bnert-time-y','/datadrive_2/bnert-time-y','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','[DATE]','year_date'),\n",
    "               ('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','[DATE]','year_date'),\n",
    "               ('bnert-pol-st','/datadrive_2/bnert-pol-st','[SEP]','year_sep'),\n",
    "               ('bnert-pol','/datadrive_2/bnert-pol','[SEP]','year_sep'),\n",
    "               ('bnert-comb','/datadrive_2/bnert-combined','[SEP]','year_sep')\n",
    "              ]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st, sent_col in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=num_labels)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    #model_dict[name]['special_token'] = st\n",
    "    model_dict[name]['sentences'] = sent_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13455536",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = train_val.remove_columns(['Unnamed: 0','SentenceCtxt', 'SentenceId', 'TargetExpression','animacy', 'humanness'])\n",
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def add_text_col(example,source):\n",
    "#    return {'text' : example[source]}\n",
    "\n",
    "def preprocess_function(examples, target_col):\n",
    "    return tokenizer(examples[target_col], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = defaultdict(dict)\n",
    "\n",
    "for name, mdict in model_dict.items():\n",
    "    print(f'Creating a model for {name}')\n",
    "    tokenizer = model_dict[name]['tokenizer']\n",
    "    model = model_dict[name]['model']\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    sent_col = model_dict[name]['sentences']\n",
    "    \n",
    "    #train_val = train_val.map(add_text_col,fn_kwargs={'source': sent_col})\n",
    "    train_val = train_val.map(preprocess_function,fn_kwargs={'target_col': sent_col})\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "    output_dir=f\"../results_{name}\",\n",
    "    seed = 42,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_val[\"train\"],\n",
    "    eval_dataset=train_val[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    model.save_pretrained(f'/datadrive_2/bnert-{name}-animacy')\n",
    "    tokenizer.save_pretrained(f\"/datadrive_2/bnert-{name}-animacy\")\n",
    "    \n",
    "    \n",
    "    test_set = test_set.map(preprocess_function,fn_kwargs={'target_col': sent_col})\n",
    "    predictions = trainer.predict(test_set)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    result_dict[name]['f1_binary'] = f1_score(preds,predictions.label_ids,average='binary')\n",
    "    result_dict[name]['f1_macro'] = f1_score(preds,predictions.label_ids,average='macro')\n",
    "    result_dict[name]['f1_micro'] = f1_score(preds,predictions.label_ids,average='micro')\n",
    "    result_dict[name]['accuracy']  = accuracy_score(preds,predictions.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d444236",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(result_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997649c6",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
