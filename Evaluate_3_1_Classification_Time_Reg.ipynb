{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0f9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import evaluate\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import DataCollatorWithPadding\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b07302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "    num_rows: 11315511\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = load_from_disk('/datadrive_2/')\n",
    "#test_data = dataset['test']\n",
    "\n",
    "cache_dir = '/datadrive_2/hf_cache/'\n",
    "dataset = load_from_disk(\"/datadrive_2/HMD_chunked_100_test/\")\n",
    "dataset #= dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a047ed",
   "metadata": {},
   "source": [
    "## Classify by Political Leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0f1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_pattern = re.compile(r'\\bliberal|\\bconservat|\\btory\\b|\\btories\\b',re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69dea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['liberal', 'conservat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_pattern.findall('liberal governments do not fire their conservative political ministers minister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2875c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sent_split(x):\n",
    "#      return {'data': [\n",
    "#                 {'sentence':s.lower(),\n",
    "#                  'length': len(s.split()),\n",
    "#                  'pol': p, 'loc':l, 'year':y, 'ocr':o,'nlp':n} \n",
    "#                      for y,p,l,o,n,t in zip(x['year'],x['pol'],x['loc'],x['ocr_quality_mean'],x['nlp'],x['text']) \n",
    "#                       for s in sent_tokenize(t) \n",
    "#                          if pol_pattern.findall(s)\n",
    "#                  ]\n",
    "#             }\n",
    "\n",
    "# test_data = dataset.map(sent_split,batched=True, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db872537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-6f3d8b9a1021878e.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-2d79338e1133aae6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-24d2a5525e368df0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-b3061892df3a5bbe.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-06bf12bcec6754fc.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-a090791e087fa494.arrow\n",
      "Loading cached shuffled indices for dataset at /datadrive_2/HMD_chunked_100_test/cache-2e3366e450e9f2f2.arrow\n"
     ]
    }
   ],
   "source": [
    "test_data = dataset.map(\n",
    "                lambda x: {'sentences': x['sentences'].lower()}, num_proc=6\n",
    "                        ).shuffle(seed=42).select(range(15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0086b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "    num_rows: 15000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de3edfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = test_data.filter(lambda x: x['data.length'] > 25).shuffle(seed=42).select(range(15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d45648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-ff0fd48ef7c4aa88.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-6aeec3fc41d9a975.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-0f45e64b62b46afe.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-a1b252da72d25d12.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-b1a1fc69d546bff6.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-4bbfb9a6d353944e.arrow\n"
     ]
    }
   ],
   "source": [
    "# def pred_data(example,add_field='year'):\n",
    "#     return {'st_year_sep': f'[{example[add_field]}]' + ' [SEP] ' + example['sentences'] ,\n",
    "#      'year_sep': str(example[add_field]) + ' [SEP] ' + example['sentences'] ,\n",
    "#      'year_date': str(example[add_field]) + ' [DATE] ' + example['sentences'],\n",
    "        \n",
    "#     }\n",
    "def pred_data(example):\n",
    "    return {'label':float(example['year'])}\n",
    "    \n",
    "data = test_data.map(pred_data , num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad873104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9989630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5a32db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lab2code = {'[con]':0,'[lib]':1,'[rad]':2,'[neutr]':3,'[none]':4}\n",
    "# num_labels = len(lab2code)\n",
    "# data = data.map(lambda x: {'label': lab2code[x['pol']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcecd756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 1859,\n",
       " 'nlp': 2084,\n",
       " 'pol': '[neutr]',\n",
       " 'loc': '[liverpool]',\n",
       " 'sentences': 'sitenirranv, roy institute as tou ry, v. ireno. i.—nervous debility, loss of kient.„2,l:oo!op orof sight, prostration of physical energy, 1;\\': asor\\'\\'business, study, or society, with dr. marston \\'01coax. men.o• heiti 0addressed specially to young 14. ...e oh 0%—marrlagerbanodbilgaltetipoltnsodanudetilrn°ooimp ten &c. \\' addressed to those who dam. 1010 . totof removing all impediments. qi thee dirpthaenß:orrrs4 2ar.cll\\'of healthful children, clearly expl.-11:91p .no. 3.—tiie great social evil. 11\\' wee voerdiseases which result from it, with da. minor ~,fc „i;,da. massrosi continues to be consulted pe ,e,:.„penned with.veoftiit.reatment, by which msactinr luso* a\\'\\'\\'s,y.o,,tifi,,:vilti9.residence,ez ens-......r5z 0 d-6 orby letter,47, eitherin at thexrßotal.lnsroittitatetßa: 1171,01\\'\"raftpaordrticeuiveargry.inf°\"\"ti°l4 70-00.',\n",
       " 'ocr': 0.643,\n",
       " 'label': 1859.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4c0efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /datadrive_2/HMD_chunked_100_test/cache-772543886c89d7f3.arrow and /datadrive_2/HMD_chunked_100_test/cache-e018be346372ac2c.arrow\n",
      "Loading cached split indices for dataset at /datadrive_2/HMD_chunked_100_test/cache-0f7c9122ef09d4a9.arrow and /datadrive_2/HMD_chunked_100_test/cache-4947f263d6c6457a.arrow\n"
     ]
    }
   ],
   "source": [
    "test_size = int(len(data)*.2)\n",
    "train_test = data.train_test_split(test_size=test_size, seed=1984)\n",
    "test_set = train_test['test']\n",
    "val_size = int(len(train_test['train'])*.15)\n",
    "train_val =  train_test['train'].train_test_split(test_size=val_size, seed=1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f7f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'label'],\n",
       "        num_rows: 10200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'label'],\n",
       "        num_rows: 1800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495b21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at /datadrive_2/bnert-hmd were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /datadrive_2/bnert-hmd and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at /datadrive_2/bnert-time-y were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /datadrive_2/bnert-time-y and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at /datadrive_2/bnert-time-y_masked_25 were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /datadrive_2/bnert-time-y_masked_25 and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at /datadrive_2/bnert-time-y_masked_75 were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /datadrive_2/bnert-time-y_masked_75 and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoints = [('distilbert','distilbert-base-uncased','[SEP]','sentences'),\n",
    "               ('hmd_distilbert','/datadrive_2/bnert-hmd','[SEP]','sentences'),\n",
    "               #('bnert-time-st-y','/datadrive_2/bnert-time-st-y','[SEP]','sentences'),\n",
    "               ('bnert-time-y','/datadrive_2/bnert-time-y','[DATE]','sentences'),\n",
    "               ('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','[DATE]','sentences'),\n",
    "               ('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','[DATE]','sentences'),\n",
    "               #('bnert-pol-st','/datadrive_2/bnert-pol-st','[SEP]','year_sep'),\n",
    "               #('bnert-pol','/datadrive_2/bnert-pol','[SEP]','sentences')\n",
    "              ]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st, sent_col in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=1)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    #model_dict[name]['special_token'] = st\n",
    "    model_dict[name]['sentences'] = sent_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f12775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'pol', 'sentences', 'label'],\n",
       "        num_rows: 10200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'pol', 'sentences', 'label'],\n",
       "        num_rows: 1800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = train_val.remove_columns(['nlp', 'ocr', 'loc'])\n",
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6fed10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def add_text_col(example,source):\n",
    "#    return {'text' : example[source]}\n",
    "\n",
    "def preprocess_function(examples, target_col):\n",
    "    return tokenizer(examples[target_col], truncation=True, padding=\"max_length\", max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a244b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    #print(labels, logits)\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "    \n",
    "    # Compute accuracy \n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e895a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-ad2d056fe0e39963.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-d25d1d2e1389c0e8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model for distilbert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/datadrive_2/lm2/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10200\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46159' max='51000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46159/51000 1:38:34 < 10:20, 7.80 it/s, Epoch 36.20/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3302758.400000</td>\n",
       "      <td>3214710.500000</td>\n",
       "      <td>3214711.000000</td>\n",
       "      <td>1792.879395</td>\n",
       "      <td>-10940.692318</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2978440.448000</td>\n",
       "      <td>2888648.750000</td>\n",
       "      <td>2888648.750000</td>\n",
       "      <td>1699.516113</td>\n",
       "      <td>-9830.897933</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2642760.704000</td>\n",
       "      <td>2413907.750000</td>\n",
       "      <td>2413907.750000</td>\n",
       "      <td>1553.580811</td>\n",
       "      <td>-8215.052705</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1990798.336000</td>\n",
       "      <td>1821300.875000</td>\n",
       "      <td>1821300.875000</td>\n",
       "      <td>1349.446899</td>\n",
       "      <td>-6198.038032</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1494567.168000</td>\n",
       "      <td>1177249.125000</td>\n",
       "      <td>1177249.125000</td>\n",
       "      <td>1084.875732</td>\n",
       "      <td>-4005.922946</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>755149.248000</td>\n",
       "      <td>578930.375000</td>\n",
       "      <td>578930.375000</td>\n",
       "      <td>760.681641</td>\n",
       "      <td>-1969.466011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>349306.176000</td>\n",
       "      <td>143939.171875</td>\n",
       "      <td>143939.187500</td>\n",
       "      <td>379.005768</td>\n",
       "      <td>-488.915990</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>15369.130000</td>\n",
       "      <td>307.340149</td>\n",
       "      <td>307.340179</td>\n",
       "      <td>13.505940</td>\n",
       "      <td>-0.046073</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2639.978800</td>\n",
       "      <td>336.012054</td>\n",
       "      <td>336.012085</td>\n",
       "      <td>13.728494</td>\n",
       "      <td>-0.143661</td>\n",
       "      <td>0.029444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2731.486000</td>\n",
       "      <td>295.118347</td>\n",
       "      <td>295.118378</td>\n",
       "      <td>13.538379</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>0.021111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2663.794500</td>\n",
       "      <td>335.201935</td>\n",
       "      <td>335.201935</td>\n",
       "      <td>13.686435</td>\n",
       "      <td>-0.140904</td>\n",
       "      <td>0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2609.172000</td>\n",
       "      <td>297.293335</td>\n",
       "      <td>297.293335</td>\n",
       "      <td>13.137918</td>\n",
       "      <td>-0.011877</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2682.998800</td>\n",
       "      <td>264.263031</td>\n",
       "      <td>264.263031</td>\n",
       "      <td>12.659463</td>\n",
       "      <td>0.100546</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2709.039000</td>\n",
       "      <td>274.339142</td>\n",
       "      <td>274.339172</td>\n",
       "      <td>13.164435</td>\n",
       "      <td>0.066250</td>\n",
       "      <td>0.027222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2509.735700</td>\n",
       "      <td>344.910706</td>\n",
       "      <td>344.910706</td>\n",
       "      <td>14.273975</td>\n",
       "      <td>-0.173949</td>\n",
       "      <td>0.021667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2594.292500</td>\n",
       "      <td>215.125900</td>\n",
       "      <td>215.125900</td>\n",
       "      <td>11.453353</td>\n",
       "      <td>0.267791</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2496.656500</td>\n",
       "      <td>223.252396</td>\n",
       "      <td>223.252396</td>\n",
       "      <td>11.704017</td>\n",
       "      <td>0.240131</td>\n",
       "      <td>0.027222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2700.509000</td>\n",
       "      <td>201.383438</td>\n",
       "      <td>201.383438</td>\n",
       "      <td>11.301710</td>\n",
       "      <td>0.314565</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2651.884000</td>\n",
       "      <td>207.170395</td>\n",
       "      <td>207.170395</td>\n",
       "      <td>11.152031</td>\n",
       "      <td>0.294868</td>\n",
       "      <td>0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2622.600800</td>\n",
       "      <td>237.253174</td>\n",
       "      <td>237.253174</td>\n",
       "      <td>11.810018</td>\n",
       "      <td>0.192477</td>\n",
       "      <td>0.037778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2583.389500</td>\n",
       "      <td>282.084106</td>\n",
       "      <td>282.084106</td>\n",
       "      <td>12.874718</td>\n",
       "      <td>0.039890</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2540.590000</td>\n",
       "      <td>220.319305</td>\n",
       "      <td>220.319305</td>\n",
       "      <td>11.554958</td>\n",
       "      <td>0.250114</td>\n",
       "      <td>0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2485.924000</td>\n",
       "      <td>217.614075</td>\n",
       "      <td>217.614075</td>\n",
       "      <td>11.331828</td>\n",
       "      <td>0.259322</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2531.185200</td>\n",
       "      <td>224.314682</td>\n",
       "      <td>224.314697</td>\n",
       "      <td>11.444019</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2460.957500</td>\n",
       "      <td>209.204376</td>\n",
       "      <td>209.204376</td>\n",
       "      <td>11.160594</td>\n",
       "      <td>0.287945</td>\n",
       "      <td>0.027222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2578.871700</td>\n",
       "      <td>200.040100</td>\n",
       "      <td>200.040085</td>\n",
       "      <td>10.956387</td>\n",
       "      <td>0.319137</td>\n",
       "      <td>0.023889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2432.235300</td>\n",
       "      <td>193.315063</td>\n",
       "      <td>193.315048</td>\n",
       "      <td>10.717463</td>\n",
       "      <td>0.342027</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2640.896500</td>\n",
       "      <td>202.239517</td>\n",
       "      <td>202.239517</td>\n",
       "      <td>11.029184</td>\n",
       "      <td>0.311651</td>\n",
       "      <td>0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2490.138800</td>\n",
       "      <td>231.969299</td>\n",
       "      <td>231.969345</td>\n",
       "      <td>11.732279</td>\n",
       "      <td>0.210462</td>\n",
       "      <td>0.023889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2507.718500</td>\n",
       "      <td>246.146942</td>\n",
       "      <td>246.146942</td>\n",
       "      <td>12.219349</td>\n",
       "      <td>0.162206</td>\n",
       "      <td>0.031111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2454.622700</td>\n",
       "      <td>188.352722</td>\n",
       "      <td>188.352707</td>\n",
       "      <td>10.593850</td>\n",
       "      <td>0.358917</td>\n",
       "      <td>0.031111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2574.407700</td>\n",
       "      <td>209.421127</td>\n",
       "      <td>209.421127</td>\n",
       "      <td>11.285171</td>\n",
       "      <td>0.287208</td>\n",
       "      <td>0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2475.385200</td>\n",
       "      <td>248.188080</td>\n",
       "      <td>248.188049</td>\n",
       "      <td>12.307270</td>\n",
       "      <td>0.155259</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2511.448800</td>\n",
       "      <td>219.212952</td>\n",
       "      <td>219.212952</td>\n",
       "      <td>11.484091</td>\n",
       "      <td>0.253880</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2465.190800</td>\n",
       "      <td>238.510208</td>\n",
       "      <td>238.510208</td>\n",
       "      <td>12.006326</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2437.731000</td>\n",
       "      <td>195.081879</td>\n",
       "      <td>195.081879</td>\n",
       "      <td>10.778882</td>\n",
       "      <td>0.336013</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results_distilbert/checkpoint-1000\n",
      "Configuration saved in ../results_distilbert/checkpoint-1000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-1500\n",
      "Configuration saved in ../results_distilbert/checkpoint-1500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-2000\n",
      "Configuration saved in ../results_distilbert/checkpoint-2000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-2500\n",
      "Configuration saved in ../results_distilbert/checkpoint-2500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-2500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-3000\n",
      "Configuration saved in ../results_distilbert/checkpoint-3000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-3500\n",
      "Configuration saved in ../results_distilbert/checkpoint-3500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-3500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-10500\n",
      "Configuration saved in ../results_distilbert/checkpoint-10500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-11000\n",
      "Configuration saved in ../results_distilbert/checkpoint-11000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-11000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-11500\n",
      "Configuration saved in ../results_distilbert/checkpoint-11500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-12000\n",
      "Configuration saved in ../results_distilbert/checkpoint-12000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-12500\n",
      "Configuration saved in ../results_distilbert/checkpoint-12500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-12500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-13000\n",
      "Configuration saved in ../results_distilbert/checkpoint-13000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-13000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-19500\n",
      "Configuration saved in ../results_distilbert/checkpoint-19500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-20000\n",
      "Configuration saved in ../results_distilbert/checkpoint-20000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-20000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-20500\n",
      "Configuration saved in ../results_distilbert/checkpoint-20500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-21000\n",
      "Configuration saved in ../results_distilbert/checkpoint-21000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-21000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-21500\n",
      "Configuration saved in ../results_distilbert/checkpoint-21500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-21500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-27500\n",
      "Configuration saved in ../results_distilbert/checkpoint-27500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-27500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-28000\n",
      "Configuration saved in ../results_distilbert/checkpoint-28000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-28000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-28500\n",
      "Configuration saved in ../results_distilbert/checkpoint-28500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../results_distilbert/checkpoint-28500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-29000\n",
      "Configuration saved in ../results_distilbert/checkpoint-29000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-29000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-29500\n",
      "Configuration saved in ../results_distilbert/checkpoint-29500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-29500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-30000\n",
      "Configuration saved in ../results_distilbert/checkpoint-30000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-30000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-36000\n",
      "Configuration saved in ../results_distilbert/checkpoint-36000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-36500\n",
      "Configuration saved in ../results_distilbert/checkpoint-36500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-36500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-37000\n",
      "Configuration saved in ../results_distilbert/checkpoint-37000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-37500\n",
      "Configuration saved in ../results_distilbert/checkpoint-37500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-37500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-38000\n",
      "Configuration saved in ../results_distilbert/checkpoint-38000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-38000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-43500\n",
      "Configuration saved in ../results_distilbert/checkpoint-43500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-43500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-44000\n",
      "Configuration saved in ../results_distilbert/checkpoint-44000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-44000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-44500\n",
      "Configuration saved in ../results_distilbert/checkpoint-44500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-44500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-45000\n",
      "Configuration saved in ../results_distilbert/checkpoint-45000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-45000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-45500\n",
      "Configuration saved in ../results_distilbert/checkpoint-45500/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-45500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_distilbert/checkpoint-46000\n",
      "Configuration saved in ../results_distilbert/checkpoint-46000/config.json\n",
      "Model weights saved in ../results_distilbert/checkpoint-46000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Configuration saved in /datadrive_2/distilbert-time-reg/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-time-reg/pytorch_model.bin\n",
      "tokenizer config file saved in /datadrive_2/distilbert-time-reg/tokenizer_config.json\n",
      "Special tokens file saved in /datadrive_2/distilbert-time-reg/special_tokens_map.json\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-2c4a708601269864.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-55b4828d2972c0a2.arrow\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/datadrive_2/lm2/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model for hmd_distilbert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51000' max='51000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51000/51000 1:46:15, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3296502.272000</td>\n",
       "      <td>3203912.250000</td>\n",
       "      <td>3203912.500000</td>\n",
       "      <td>1789.865601</td>\n",
       "      <td>-10903.938865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2958414.336000</td>\n",
       "      <td>2865517.500000</td>\n",
       "      <td>2865517.500000</td>\n",
       "      <td>1692.697266</td>\n",
       "      <td>-9752.167194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2610553.088000</td>\n",
       "      <td>2373336.250000</td>\n",
       "      <td>2373336.000000</td>\n",
       "      <td>1540.468140</td>\n",
       "      <td>-8076.962791</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1937870.848000</td>\n",
       "      <td>1763342.125000</td>\n",
       "      <td>1763342.125000</td>\n",
       "      <td>1327.798340</td>\n",
       "      <td>-6000.767506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1429087.104000</td>\n",
       "      <td>1107510.000000</td>\n",
       "      <td>1107510.000000</td>\n",
       "      <td>1052.243408</td>\n",
       "      <td>-3768.556674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>686757.184000</td>\n",
       "      <td>511111.218750</td>\n",
       "      <td>511111.250000</td>\n",
       "      <td>714.714844</td>\n",
       "      <td>-1738.634552</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>290169.056000</td>\n",
       "      <td>101008.023438</td>\n",
       "      <td>101008.023438</td>\n",
       "      <td>317.355042</td>\n",
       "      <td>-342.794155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5616.255000</td>\n",
       "      <td>295.312561</td>\n",
       "      <td>295.312561</td>\n",
       "      <td>13.649311</td>\n",
       "      <td>-0.005135</td>\n",
       "      <td>0.035556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2608.175200</td>\n",
       "      <td>319.701508</td>\n",
       "      <td>319.701538</td>\n",
       "      <td>13.570998</td>\n",
       "      <td>-0.088146</td>\n",
       "      <td>0.022778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2625.496700</td>\n",
       "      <td>293.777710</td>\n",
       "      <td>293.777710</td>\n",
       "      <td>14.204852</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.008889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2473.937000</td>\n",
       "      <td>406.058228</td>\n",
       "      <td>406.058228</td>\n",
       "      <td>15.115263</td>\n",
       "      <td>-0.382073</td>\n",
       "      <td>0.028889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2477.883700</td>\n",
       "      <td>261.358643</td>\n",
       "      <td>261.358643</td>\n",
       "      <td>12.383455</td>\n",
       "      <td>0.110431</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2542.354700</td>\n",
       "      <td>316.407013</td>\n",
       "      <td>316.407013</td>\n",
       "      <td>13.768066</td>\n",
       "      <td>-0.076933</td>\n",
       "      <td>0.026111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2558.726300</td>\n",
       "      <td>278.638794</td>\n",
       "      <td>278.638763</td>\n",
       "      <td>13.001945</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2514.609800</td>\n",
       "      <td>245.417633</td>\n",
       "      <td>245.417633</td>\n",
       "      <td>12.114478</td>\n",
       "      <td>0.164689</td>\n",
       "      <td>0.021667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2433.500500</td>\n",
       "      <td>325.126312</td>\n",
       "      <td>325.126312</td>\n",
       "      <td>14.273486</td>\n",
       "      <td>-0.106610</td>\n",
       "      <td>0.026111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2523.564500</td>\n",
       "      <td>222.424408</td>\n",
       "      <td>222.424408</td>\n",
       "      <td>11.521589</td>\n",
       "      <td>0.242949</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2477.950200</td>\n",
       "      <td>410.875244</td>\n",
       "      <td>410.875214</td>\n",
       "      <td>16.099754</td>\n",
       "      <td>-0.398468</td>\n",
       "      <td>0.022778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2505.936000</td>\n",
       "      <td>322.266693</td>\n",
       "      <td>322.266693</td>\n",
       "      <td>13.718915</td>\n",
       "      <td>-0.096877</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2393.023700</td>\n",
       "      <td>379.295288</td>\n",
       "      <td>379.295288</td>\n",
       "      <td>15.585804</td>\n",
       "      <td>-0.290982</td>\n",
       "      <td>0.018889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2497.836700</td>\n",
       "      <td>342.186462</td>\n",
       "      <td>342.186462</td>\n",
       "      <td>14.314547</td>\n",
       "      <td>-0.164677</td>\n",
       "      <td>0.033889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2479.760000</td>\n",
       "      <td>184.651764</td>\n",
       "      <td>184.651764</td>\n",
       "      <td>10.591711</td>\n",
       "      <td>0.371513</td>\n",
       "      <td>0.031667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2418.244500</td>\n",
       "      <td>257.194702</td>\n",
       "      <td>257.194702</td>\n",
       "      <td>12.387442</td>\n",
       "      <td>0.124604</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2417.249200</td>\n",
       "      <td>259.542694</td>\n",
       "      <td>259.542694</td>\n",
       "      <td>12.423093</td>\n",
       "      <td>0.116612</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2399.470000</td>\n",
       "      <td>250.635101</td>\n",
       "      <td>250.635117</td>\n",
       "      <td>12.314262</td>\n",
       "      <td>0.146930</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2484.474700</td>\n",
       "      <td>245.817261</td>\n",
       "      <td>245.817261</td>\n",
       "      <td>12.260948</td>\n",
       "      <td>0.163329</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2380.217000</td>\n",
       "      <td>165.874908</td>\n",
       "      <td>165.874908</td>\n",
       "      <td>9.983235</td>\n",
       "      <td>0.435423</td>\n",
       "      <td>0.037222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2467.413500</td>\n",
       "      <td>263.192505</td>\n",
       "      <td>263.192505</td>\n",
       "      <td>12.676826</td>\n",
       "      <td>0.104190</td>\n",
       "      <td>0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2438.067500</td>\n",
       "      <td>263.701233</td>\n",
       "      <td>263.701263</td>\n",
       "      <td>12.737912</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>0.036667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2397.160800</td>\n",
       "      <td>263.053345</td>\n",
       "      <td>263.053345</td>\n",
       "      <td>12.673709</td>\n",
       "      <td>0.104663</td>\n",
       "      <td>0.031111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2361.180200</td>\n",
       "      <td>209.713760</td>\n",
       "      <td>209.713745</td>\n",
       "      <td>11.110066</td>\n",
       "      <td>0.286212</td>\n",
       "      <td>0.029444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2296.455200</td>\n",
       "      <td>181.645798</td>\n",
       "      <td>181.645782</td>\n",
       "      <td>10.413737</td>\n",
       "      <td>0.381745</td>\n",
       "      <td>0.037222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2351.010700</td>\n",
       "      <td>250.376663</td>\n",
       "      <td>250.376663</td>\n",
       "      <td>12.256348</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2394.899200</td>\n",
       "      <td>215.497452</td>\n",
       "      <td>215.497452</td>\n",
       "      <td>11.222115</td>\n",
       "      <td>0.266526</td>\n",
       "      <td>0.028889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2413.834700</td>\n",
       "      <td>181.692184</td>\n",
       "      <td>181.692184</td>\n",
       "      <td>10.425889</td>\n",
       "      <td>0.381587</td>\n",
       "      <td>0.036667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2348.673700</td>\n",
       "      <td>218.734024</td>\n",
       "      <td>218.734024</td>\n",
       "      <td>11.426402</td>\n",
       "      <td>0.255510</td>\n",
       "      <td>0.035556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2358.695700</td>\n",
       "      <td>209.617233</td>\n",
       "      <td>209.617233</td>\n",
       "      <td>11.191881</td>\n",
       "      <td>0.286540</td>\n",
       "      <td>0.027222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2443.187800</td>\n",
       "      <td>247.805466</td>\n",
       "      <td>247.805450</td>\n",
       "      <td>12.258964</td>\n",
       "      <td>0.156561</td>\n",
       "      <td>0.037222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2358.088700</td>\n",
       "      <td>228.914566</td>\n",
       "      <td>228.914566</td>\n",
       "      <td>11.738732</td>\n",
       "      <td>0.220859</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2404.373300</td>\n",
       "      <td>203.703125</td>\n",
       "      <td>203.703125</td>\n",
       "      <td>10.990513</td>\n",
       "      <td>0.306669</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-1000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-1000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-1500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-1500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-2000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-2000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-2500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-2500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-2500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-9500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-9500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-10000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-10000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-10000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-10500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-10500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-11000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-11000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-11000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-11500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-11500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-12000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-12000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-12000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-18000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-18000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-18500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-18500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-19000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-19000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-19000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-19500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-19500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-20000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-20000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-20000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-20500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-20500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-20500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-26500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-26500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-26500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-27000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-27000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-27500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-27500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-27500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-28000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-28000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-28000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-28500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-28500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-28500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-29000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-29000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-29000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-35000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-35000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-35500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-35500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-35500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-36000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-36000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-36500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-36500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-36500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-37000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-37000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-37500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-37500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-37500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-43000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-43000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-43000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-43500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-43500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-43500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-44000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-44000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-44000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-44500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-44500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-44500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-45000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-45000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-45000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-45500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-45500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-45500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-50000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-50000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-50000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-50500\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-50500/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-50500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_hmd_distilbert/checkpoint-51000\n",
      "Configuration saved in ../results_hmd_distilbert/checkpoint-51000/config.json\n",
      "Model weights saved in ../results_hmd_distilbert/checkpoint-51000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-0e3eed62b4d44f6a.arrow\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, year, ocr, loc, pol, nlp. If sentences, year, ocr, loc, pol, nlp are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, year, ocr, loc, pol, nlp. If sentences, year, ocr, loc, pol, nlp are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 8\n",
      "Configuration saved in /datadrive_2/hmd_distilbert-time-reg/config.json\n",
      "Model weights saved in /datadrive_2/hmd_distilbert-time-reg/pytorch_model.bin\n",
      "tokenizer config file saved in /datadrive_2/hmd_distilbert-time-reg/tokenizer_config.json\n",
      "Special tokens file saved in /datadrive_2/hmd_distilbert-time-reg/special_tokens_map.json\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-cead509d66e37495.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_test/cache-a23699cca14a5879.arrow\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/datadrive_2/lm2/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10200\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model for bnert-time-y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27764' max='51000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27764/51000 58:46 < 49:11, 7.87 it/s, Epoch 21.77/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3296848.640000</td>\n",
       "      <td>3206718.250000</td>\n",
       "      <td>3206718.500000</td>\n",
       "      <td>1790.649170</td>\n",
       "      <td>-10913.489351</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2969220.096000</td>\n",
       "      <td>2879951.250000</td>\n",
       "      <td>2879951.750000</td>\n",
       "      <td>1696.955444</td>\n",
       "      <td>-9801.295608</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2636109.824000</td>\n",
       "      <td>2410068.750000</td>\n",
       "      <td>2410068.500000</td>\n",
       "      <td>1552.344849</td>\n",
       "      <td>-8201.986624</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1993128.960000</td>\n",
       "      <td>1825652.375000</td>\n",
       "      <td>1825652.375000</td>\n",
       "      <td>1351.058228</td>\n",
       "      <td>-6212.848543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1502860.032000</td>\n",
       "      <td>1190133.000000</td>\n",
       "      <td>1190133.000000</td>\n",
       "      <td>1090.797485</td>\n",
       "      <td>-4049.774819</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>772839.360000</td>\n",
       "      <td>596766.562500</td>\n",
       "      <td>596766.625000</td>\n",
       "      <td>772.316528</td>\n",
       "      <td>-2030.174087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>366656.416000</td>\n",
       "      <td>158582.968750</td>\n",
       "      <td>158582.968750</td>\n",
       "      <td>397.855682</td>\n",
       "      <td>-538.758122</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20544.850000</td>\n",
       "      <td>299.933472</td>\n",
       "      <td>299.933472</td>\n",
       "      <td>14.517337</td>\n",
       "      <td>-0.020863</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2700.289200</td>\n",
       "      <td>297.162842</td>\n",
       "      <td>297.162872</td>\n",
       "      <td>13.571680</td>\n",
       "      <td>-0.011433</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2822.433300</td>\n",
       "      <td>317.207855</td>\n",
       "      <td>317.207855</td>\n",
       "      <td>13.552204</td>\n",
       "      <td>-0.079659</td>\n",
       "      <td>0.026111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2719.756200</td>\n",
       "      <td>340.549103</td>\n",
       "      <td>340.549103</td>\n",
       "      <td>13.788294</td>\n",
       "      <td>-0.159104</td>\n",
       "      <td>0.029444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2728.066000</td>\n",
       "      <td>310.706329</td>\n",
       "      <td>310.706329</td>\n",
       "      <td>13.340980</td>\n",
       "      <td>-0.057530</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2652.311000</td>\n",
       "      <td>210.874451</td>\n",
       "      <td>210.874420</td>\n",
       "      <td>11.473374</td>\n",
       "      <td>0.282261</td>\n",
       "      <td>0.024444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2606.292200</td>\n",
       "      <td>362.745514</td>\n",
       "      <td>362.745514</td>\n",
       "      <td>14.711739</td>\n",
       "      <td>-0.234652</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2659.722700</td>\n",
       "      <td>245.120895</td>\n",
       "      <td>245.120895</td>\n",
       "      <td>11.980994</td>\n",
       "      <td>0.165699</td>\n",
       "      <td>0.031667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2628.001700</td>\n",
       "      <td>185.679855</td>\n",
       "      <td>185.679855</td>\n",
       "      <td>10.630318</td>\n",
       "      <td>0.368014</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2582.585300</td>\n",
       "      <td>179.254745</td>\n",
       "      <td>179.254745</td>\n",
       "      <td>10.678939</td>\n",
       "      <td>0.389883</td>\n",
       "      <td>0.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2617.545000</td>\n",
       "      <td>263.438232</td>\n",
       "      <td>263.438263</td>\n",
       "      <td>12.492433</td>\n",
       "      <td>0.103353</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2701.013000</td>\n",
       "      <td>173.553940</td>\n",
       "      <td>173.553955</td>\n",
       "      <td>10.182255</td>\n",
       "      <td>0.409286</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2684.127500</td>\n",
       "      <td>197.374451</td>\n",
       "      <td>197.374451</td>\n",
       "      <td>10.954542</td>\n",
       "      <td>0.328210</td>\n",
       "      <td>0.028889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2624.517200</td>\n",
       "      <td>223.181274</td>\n",
       "      <td>223.181244</td>\n",
       "      <td>11.448879</td>\n",
       "      <td>0.240373</td>\n",
       "      <td>0.032778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-1500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-1500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-2000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-2000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-2000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-8000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-8000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-8500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-8500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-8500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-9000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-9000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-9500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-9500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-9500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-10500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-10500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-11000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-11000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-11000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-17000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-17000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-17500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-17500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-17500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-18000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-18000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-18500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-18500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-19000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-19000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-19000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-25000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-25000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-25500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-25500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-25500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-26000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-26000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-26000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-26500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-26500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-26500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentences, pol, year. If sentences, pol, year are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-27000\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-27000/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to ../results_bnert-time-y/checkpoint-27500\n",
      "Configuration saved in ../results_bnert-time-y/checkpoint-27500/config.json\n",
      "Model weights saved in ../results_bnert-time-y/checkpoint-27500/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dict = defaultdict(dict)\n",
    "\n",
    "for name, mdict in model_dict.items():\n",
    "    print(f'Creating a model for {name}')\n",
    "    tokenizer = model_dict[name]['tokenizer']\n",
    "    model = model_dict[name]['model']\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    sent_col = model_dict[name]['sentences']\n",
    "    \n",
    "    #train_val = train_val.map(add_text_col,fn_kwargs={'source': sent_col})\n",
    "    train_val = train_val.map(preprocess_function,fn_kwargs={'target_col': sent_col})\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "    seed=1984,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    output_dir=f\"../results_{name}\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=40,\n",
    "    weight_decay=0.05,\n",
    "        )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_val[\"train\"],\n",
    "#     eval_dataset=train_val[\"test\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#         )\n",
    "\n",
    "\n",
    "#     trainer.train()\n",
    "\n",
    "    trainer = RegressionTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_val[\"train\"],\n",
    "        eval_dataset=train_val[\"test\"],\n",
    "        compute_metrics=compute_metrics_for_regression,\n",
    "        )\n",
    "\n",
    "    trainer.train()\n",
    "    test_set = test_set.map(preprocess_function,fn_kwargs={'target_col': sent_col})\n",
    "    trainer.eval_dataset=test_set\n",
    "    trainer.evaluate()\n",
    "    scores = trainer.evaluate()\n",
    "    #print(scores)\n",
    "    model.save_pretrained(f'/datadrive_2/{name}-time-reg')\n",
    "    tokenizer.save_pretrained(f\"/datadrive_2/{name}-time-reg\")\n",
    "    \n",
    "    \n",
    "    result_dict[name]['loss'] = scores['eval_loss']\n",
    "    result_dict[name]['mae'] = scores['eval_mae']\n",
    "    result_dict[name]['mse'] = scores['eval_mse']\n",
    "    result_dict[name]['accuracy']  = scores['eval_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52123841",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(result_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60d00595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &     loss &     mae &      mse &  accuracy \\\\\n",
      "\\midrule\n",
      "distilbert     &  202.908 &  11.098 &  202.908 &     0.028 \\\\\n",
      "hmd\\_distilbert &  210.152 &  11.300 &  210.152 &     0.031 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1100391/2842510611.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.round(3).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(results_df.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('tables/classsify_time_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f6b78a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>354.605835</td>\n",
       "      <td>15.147977</td>\n",
       "      <td>354.605835</td>\n",
       "      <td>0.021667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hmd_distilbert</td>\n",
       "      <td>354.234924</td>\n",
       "      <td>15.323492</td>\n",
       "      <td>354.234924</td>\n",
       "      <td>0.021667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bnert-time-y</td>\n",
       "      <td>313.964966</td>\n",
       "      <td>14.556096</td>\n",
       "      <td>313.964966</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bnert-time-y_masked_25</td>\n",
       "      <td>323.114471</td>\n",
       "      <td>14.468663</td>\n",
       "      <td>323.114471</td>\n",
       "      <td>0.020333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bnert-time-y_masked_75</td>\n",
       "      <td>338.570129</td>\n",
       "      <td>15.287087</td>\n",
       "      <td>338.570129</td>\n",
       "      <td>0.014333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0        loss        mae         mse  accuracy\n",
       "0              distilbert  354.605835  15.147977  354.605835  0.021667\n",
       "1          hmd_distilbert  354.234924  15.323492  354.234924  0.021667\n",
       "2            bnert-time-y  313.964966  14.556096  313.964966  0.018000\n",
       "3  bnert-time-y_masked_25  323.114471  14.468663  323.114471  0.020333\n",
       "4  bnert-time-y_masked_75  338.570129  15.287087  338.570129  0.014333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.read_csv('tables/classsify_time_1.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d29c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8bc70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
