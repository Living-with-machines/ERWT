{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65456950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cdf29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/datadrive_2/frozen_corpus')\n",
    "\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1baf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2f3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-573058092beebe7f.arrow\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data.map(lambda examples: {'sentences': [x.lower() for x in examples['sentences']]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31df5277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34bd2fc01914a9dbdc1ab322b4cc74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/417 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba55f98bb8243a9a208905a8042e8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/417 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f6e6fd7f1d4694944ba531acc23b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/417 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23098fdc64bd446daabe764a332b20ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/417 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15587f60cec441ba6c1f6254e3cd35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/416 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2689524a2ee493ab43fccf245ad6039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/416 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lab2token = {'[lib]':'liberal', '[con]':'conservative', '[none]':'none', '[rad]':'radical', '[neutr]':'neutral'}\n",
    "\n",
    "def pred_data(example):\n",
    "    return {'st_pol_sent': f'{example[\"pol\"]}' + ' [POL] ' + example['sentences'] ,\n",
    "            'pol_sent': lab2token[example['pol']] + ' [POL] ' + example['sentences'] ,\n",
    "         \n",
    "    }\n",
    "    \n",
    "test_data = test_data.map(pred_data , num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc4743c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3575b3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'st_pol_sent', 'pol_sent', 'loss_bnert-pol-st', 'loss_bnert-pol'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "495a8455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 1849,\n",
       " 'nlp': 2194,\n",
       " 'pol': '[lib]',\n",
       " 'loc': '[london]',\n",
       " 'sentences': \"don't you cry for me,i'm going to moses' warehouse, as the best that i can see.i'll also buy a paletot,for ordinary wear,and sure i am that i shall getau out-and-out affair.moses and son i hear have gota plentiful supply.and none can equal it, 'us said,so rivals don't you try.no, poor rivals, don't you try for me.i'm going to moses' warehouse, as the best that i can see.coat, vest, and trowsers, boots and hat,i'll buy without demur,my lady, too, shall have a muff,for i must think of her.i know the prices here are low,although the goods rank high,and none can contradict\",\n",
       " 'ocr': 0.8797,\n",
       " 'length': 100,\n",
       " 'st_pol_sent': \"[lib] [POL] don't you cry for me,i'm going to moses' warehouse, as the best that i can see.i'll also buy a paletot,for ordinary wear,and sure i am that i shall getau out-and-out affair.moses and son i hear have gota plentiful supply.and none can equal it, 'us said,so rivals don't you try.no, poor rivals, don't you try for me.i'm going to moses' warehouse, as the best that i can see.coat, vest, and trowsers, boots and hat,i'll buy without demur,my lady, too, shall have a muff,for i must think of her.i know the prices here are low,although the goods rank high,and none can contradict\",\n",
       " 'pol_sent': \"liberal [POL] don't you cry for me,i'm going to moses' warehouse, as the best that i can see.i'll also buy a paletot,for ordinary wear,and sure i am that i shall getau out-and-out affair.moses and son i hear have gota plentiful supply.and none can equal it, 'us said,so rivals don't you try.no, poor rivals, don't you try for me.i'm going to moses' warehouse, as the best that i can see.coat, vest, and trowsers, boots and hat,i'll buy without demur,my lady, too, shall have a muff,for i must think of her.i know the prices here are low,although the goods rank high,and none can contradict\",\n",
       " 'loss_bnert-pol-st': 6.895163519787762,\n",
       " 'loss_bnert-pol': 7.061158670365988}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e74e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [#('distilbert','distilbert-base-uncased','[SEP]','year_sep'),\n",
    "               #('hmd_distilbert','/datadrive_2/bnert-hmd','[SEP]','year_sep'),\n",
    "               ('bnert-pol-st','/datadrive_2/bnert-pol-st','[POL]','st_pol_sent'),\n",
    "               ('bnert-pol','/datadrive_2/bnert-pol','[POL]','pol_sent'),\n",
    "               #('bnert-time-y_masked_25','/datadrive_2/bnert-time-y_masked_25','[DATE]','year_date'),\n",
    "               #('bnert-time-y_masked_75','/datadrive_2/bnert-time-y_masked_75','[DATE]','year_date')\n",
    "]\n",
    "\n",
    "model_dict = defaultdict(dict)\n",
    "for name,checkpoint, st, sent_col in checkpoints:\n",
    "    model_dict[name]['model'] = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "    model_dict[name]['tokenizer'] = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    #model_dict[name]['special_token'] = st\n",
    "    model_dict[name]['sentences'] = sent_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b4cfe",
   "metadata": {},
   "source": [
    "Code adapted from this [Stack Overflow](\n",
    "https://stackoverflow.com/questions/70464428/how-to-calculate-perplexity-of-a-sentence-using-huggingface-masked-language-mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd9d13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_perplexity(example, sent_col, name, model, tokenizer):\n",
    "    tensor_input = tokenizer.encode(example[sent_col], return_tensors='pt',truncation=True, max_length=128)\n",
    "    #print(tensor_input.shape)\n",
    "    #if with_meta:\n",
    "    repeat_input = tensor_input.repeat(tensor_input.size(-1)-4, 1)\n",
    "    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[2:-2]\n",
    "    #else:\n",
    "    #    repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
    "    #    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
    "    masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "    labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "    with torch.inference_mode():\n",
    "        loss = model(masked_input, labels=labels).loss\n",
    "    return {f'loss_{name}':np.exp(loss.item())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b672126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-pol-st\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9e1ea149d04e56a570042b894d8edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bnert-pol\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636a7ee6061b4ec8b8eb416bb668b7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, ndict in model_dict.items():\n",
    "    print(f'Evaluating {name}')\n",
    "    test_data = test_data.map(pseudo_perplexity, \n",
    "                              #num_proc=3,\n",
    "                              fn_kwargs={'sent_col':ndict['sentences'],\n",
    "                                        'name': name,\n",
    "                                        'model':ndict['model'],\n",
    "                                        'tokenizer':ndict['tokenizer']  \n",
    "                                   }\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b49ef60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_data.remove_columns(['nlp','loc','length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2931a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0d96177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a7e0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['pol'] = results_df.pol.apply(lambda x: x.lstrip('[').rstrip(']'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e996a2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_bnert-pol-st    44.998926\n",
       "loss_bnert-pol       44.995695\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[c for c in results_df.columns if c.startswith('loss')]].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7dcf03d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classsify_pol_regex\t  pseudo_perplexity_1000ex_l28.csv  year_pred.csv\r\n",
      "classsify_pol_with_regex  pseudo_perplexity_2500ex_64.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "659461a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_128 = pd.read_csv('tables/pseudo_perplexity_1000ex_l28.csv')\n",
    "results_df_64 = pd.read_csv('tables/pseudo_perplexity_2500ex_64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "93398549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.to_csv('tables/pseudo_perplexity_2500ex_64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1b07d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_64['dec'] = results_df_64.year.apply(lambda x: int(str(x)[:3]+'0'))\n",
    "results_df_128['dec'] = results_df_128.year.apply(lambda x: int(str(x)[:3]+'0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "f75c468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_64 = results_df_64[[c for c in results_df_64.columns if c.startswith('loss')]].sum(axis=0) \n",
    "scores_128 = results_df_128[[c for c in results_df_128.columns if c.startswith('loss')]].sum(axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "83d5da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &        0 &         1 \\\\\n",
      "\\midrule\n",
      "loss\\_hmd\\_distilbert         &  82338.0 &   25724.0 \\\\\n",
      "loss\\_bnert-time-st-y        &  79231.0 &   25030.0 \\\\\n",
      "loss\\_bnert-time-y           &  78720.0 &   24970.0 \\\\\n",
      "loss\\_bnert-time-y\\_masked\\_25 &  77424.0 &   24589.0 \\\\\n",
      "loss\\_bnert-time-y\\_masked\\_75 &  77553.0 &   24630.0 \\\\\n",
      "loss\\_distilbert             &      NaN &  229192.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_238407/3775770335.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(pd.concat([scores_64,scores_128],axis=1).round(0).to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([scores_64,scores_128],axis=1).round(0).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f4354749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "c084d46c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['pol'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [322]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_df_64 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df_64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m results_df_64\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/pandas/core/reshape/reshape.py:931\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name):\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/datadrive_2/lm2/lib/python3.9/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['pol'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "results_df_64 = pd.get_dummies(results_df_64, columns=['pol'])\n",
    "#results_df_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4402ba04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>tm25</td>       <th>  R-squared:         </th> <td>   0.323</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.321</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   197.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Aug 2022</td> <th>  Prob (F-statistic):</th> <td>1.11e-206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:06:49</td>     <th>  Log-Likelihood:    </th> <td> -13357.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2500</td>      <th>  AIC:               </th> <td>2.673e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2493</td>      <th>  BIC:               </th> <td>2.677e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> -160.4724</td> <td>  110.271</td> <td>   -1.455</td> <td> 0.146</td> <td> -376.706</td> <td>   55.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ocr</th>       <td> -254.6803</td> <td>    8.052</td> <td>  -31.629</td> <td> 0.000</td> <td> -270.470</td> <td> -238.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dec</th>       <td>    0.2405</td> <td>    0.073</td> <td>    3.305</td> <td> 0.001</td> <td>    0.098</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_con</th>   <td>  -35.1428</td> <td>   22.617</td> <td>   -1.554</td> <td> 0.120</td> <td>  -79.492</td> <td>    9.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_lib</th>   <td>  -37.0012</td> <td>   22.908</td> <td>   -1.615</td> <td> 0.106</td> <td>  -81.922</td> <td>    7.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_neutr</th> <td>  -46.6745</td> <td>   24.122</td> <td>   -1.935</td> <td> 0.053</td> <td>  -93.976</td> <td>    0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_none</th>  <td>  -25.4700</td> <td>   20.880</td> <td>   -1.220</td> <td> 0.223</td> <td>  -66.415</td> <td>   15.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pol_rad</th>   <td>  -16.1839</td> <td>   21.308</td> <td>   -0.760</td> <td> 0.448</td> <td>  -57.966</td> <td>   25.598</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2439.137</td> <th>  Durbin-Watson:     </th>  <td>   2.010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>151150.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 4.605</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>39.962</td>  <th>  Cond. No.          </th>  <td>3.00e+19</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.39e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   tm25   R-squared:                       0.323\n",
       "Model:                            OLS   Adj. R-squared:                  0.321\n",
       "Method:                 Least Squares   F-statistic:                     197.9\n",
       "Date:                Wed, 31 Aug 2022   Prob (F-statistic):          1.11e-206\n",
       "Time:                        14:06:49   Log-Likelihood:                -13357.\n",
       "No. Observations:                2500   AIC:                         2.673e+04\n",
       "Df Residuals:                    2493   BIC:                         2.677e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   -160.4724    110.271     -1.455      0.146    -376.706      55.761\n",
       "ocr         -254.6803      8.052    -31.629      0.000    -270.470    -238.891\n",
       "dec            0.2405      0.073      3.305      0.001       0.098       0.383\n",
       "pol_con      -35.1428     22.617     -1.554      0.120     -79.492       9.206\n",
       "pol_lib      -37.0012     22.908     -1.615      0.106     -81.922       7.920\n",
       "pol_neutr    -46.6745     24.122     -1.935      0.053     -93.976       0.627\n",
       "pol_none     -25.4700     20.880     -1.220      0.223     -66.415      15.475\n",
       "pol_rad      -16.1839     21.308     -0.760      0.448     -57.966      25.598\n",
       "==============================================================================\n",
       "Omnibus:                     2439.137   Durbin-Watson:                   2.010\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           151150.049\n",
       "Skew:                           4.605   Prob(JB):                         0.00\n",
       "Kurtosis:                      39.962   Cond. No.                     3.00e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.39e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_64['tm25'] = results_df_64[\"loss_bnert-time-y_masked_25\"]\n",
    "mod = smf.ols(formula='tm25 ~ ocr + dec + pol_con + pol_lib + pol_neutr + pol_none + pol_rad', data=results_df_64)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7263ba10",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa0d3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_random_mask(model, tokenizer, sentence,meta_pos=None):\n",
    "#     tensor_input = tokenizer.encode(sentence, return_tensors='pt')\n",
    "#     #print(tensor_input)\n",
    "#     repeat_input = torch.clone(tensor_input)\n",
    "#     #print(repeat_input)\n",
    "#     sum_mask,i = 0,0\n",
    "#     while sum_mask == 0:\n",
    "#         mask = torch.tensor(np.random.binomial(1, .15, repeat_input.shape[1]))\n",
    "#         sum_mask = sum(mask)\n",
    "        \n",
    "#     if meta_pos:\n",
    "#         mask[meta_pos] = 0\n",
    "#     masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "#     print(masked_input)\n",
    "#     labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "#     print(labels)\n",
    "#     with torch.inference_mode():\n",
    "#         loss = model(masked_input, labels=labels).loss\n",
    "#     return np.exp(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e25d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=lm_datasets[\"train\"],\n",
    "#     eval_dataset=lm_datasets[\"test\"],\n",
    "#     data_collator=data_collator,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm2",
   "language": "python",
   "name": "lm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
