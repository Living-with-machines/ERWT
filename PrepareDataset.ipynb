{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a52513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset,load_from_disk\n",
    "from transformers import Trainer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641da24",
   "metadata": {},
   "source": [
    "Load the pretrained model and tokenizer. Given the limited size of the data we opted for a distilbert instead of BERT model for the initial experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d54d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_checkpoint = \"distilbert-base-uncased\"\n",
    "#model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d69bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#special_tokens_dict = {'additional_special_tokens': ['[MET]','[POL]','[LOC]','[YEAR]']}\n",
    "#tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b7323",
   "metadata": {},
   "source": [
    "We set a directory for caching the dataset files, otherwise the `/home` directory will overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ad6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/datadrive_2/hf_cache/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd88caf",
   "metadata": {},
   "source": [
    "## Load Dataset and filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d03ad8d",
   "metadata": {},
   "source": [
    "Import the datasets from the HuggingFace hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"davanstrien/hmd_newspapers\", cache_dir=cache_dir)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09efdbf2",
   "metadata": {},
   "source": [
    "Because some files seem to lack a date, we filter first to avoid errors later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: (x['date'] is not None) \\\n",
    "                         or (x['ocr_quality_mean'] is not None), num_proc=6)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e46c72",
   "metadata": {},
   "source": [
    "## Link Data\n",
    "\n",
    "In this section of the notebook we focus on further enriching an contextualizing the data by adding the political leaning as a variable. We also add the NLP identifier (used by FMP) which can be used later for adding metadata.\n",
    "\n",
    "We will map the political leaning to special tokens added to the tokenizer instance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from NLP to political leaning\n",
    "# this is created semi-manually for this limited dataset\n",
    "nlp2pol = {2083:'neutral',\n",
    " 2084:'neutral',\n",
    " 2085:'neutral',\n",
    " 2088:'conservative',\n",
    " 2089:'conservative',\n",
    " 2090:'conservative',\n",
    " 2194:'liberal',\n",
    " 2244:'none',\n",
    " 2642:'liberal',\n",
    " 2643:'conservative', # not found\n",
    " 2644:'conservative',\n",
    " 2645:'conservative',\n",
    " 2646:'none', # https://en.wikipedia.org/wiki/The_Star_(1788)\n",
    " 2647:'radical', # https://www.britishnewspaperarchive.co.uk/titles/statesman-london\n",
    "}\n",
    "\n",
    "pol2code = {'none':'[none]','neutral':'[neutr]','conservative':'[con]','liberal':'[lib]','radical':'[rad]'}\n",
    "\n",
    "loc2code = {'Liverpool, Merseyside, England':'[liverpool]', 'London, England':'[london]'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b08ce",
   "metadata": {},
   "source": [
    "Because the original data lacks an NLP identifier for now, we add it via the title. For this we first need to create a mapping between NLP and titles for each publication year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06352690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "nlp_dict = defaultdict(dict)\n",
    "url = 'https://raw.githubusercontent.com/Living-with-machines/hmd_url_generator/main/HMD_title_urls.json'\n",
    "data = requests.get(url).json()\n",
    "for newspaper, year_dict in data.items():\n",
    "    for year, info_dict in year_dict.items():\n",
    "        if info_dict['fname'].endswith('zip'):\n",
    "            nlp_dict[newspaper][int(year)] = int(info_dict['fname'].split('_')[1])\n",
    "nlp_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bfc82",
   "metadata": {},
   "source": [
    "To match the titles between the `dataset` and the `nlp_dict` we need just one more dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtitle2title = {'The Northern Daily Times.':'The Northern Daily Times etc',\n",
    " 'Northern Times.':'The Northern Daily Times etc',\n",
    " 'The Daily Times.':'The Northern Daily Times etc',\n",
    " 'The Liverpool Standard and General Commercial Advertiser.':'The Liverpool Standard etc',\n",
    " 'The Liverpool Standard, and General Advertiser.':'The Liverpool Standard etc',\n",
    " 'The Sun.':'The Sun',\n",
    " 'Colored News.':'Colored News',\n",
    " 'The Express.':'The Express',\n",
    " 'The National Register.':'National Register.',\n",
    " 'The Press.':'The Press.',\n",
    " 'Star.':'The Star',\n",
    " 'The Statesman.':'The Statesman'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f452f4b",
   "metadata": {},
   "source": [
    "## Prepare Chunked Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7863f6b",
   "metadata": {},
   "source": [
    "The code below extends information on each article by\n",
    "- splitting the date into year and month\n",
    "- add an NLP identifier as well codes for location and political leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7535443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cols(example):\n",
    "\n",
    "    nlp = nlp_dict[dtitle2title[example['title']]][example['date'].year]\n",
    "    \n",
    "    return {'year': example['date'].year,\n",
    "            'length': len(example['text'].split()),\n",
    "            'month': example['date'].month,\n",
    "            'nlp' : nlp,\n",
    "            'pol': pol2code[nlp2pol[nlp]],\n",
    "            'loc': loc2code[example['location']]\n",
    "           }\n",
    "\n",
    "\n",
    "dataset = dataset.map(add_cols , num_proc=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk('/datadrive_2/HMD_context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.Series(dataset['train']['length'])\n",
    "lengths.plot(kind='hist',bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed33ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lengths > 100) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f385b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_long = dataset.filter(lambda x: x['length'] >= 100, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['train']),len(dataset_long['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885c503",
   "metadata": {},
   "source": [
    "After replacing the columns with codes we can remove some information from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd060c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_long = dataset_long['train'].remove_columns(['title', 'location', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_small = dataset.shuffle(seed=0).select(range(100_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include_cols = []\n",
    "\n",
    "# def sent_split(x):\n",
    "#      return {'data': [\n",
    "#                 {'sentence':s.lower(),\n",
    "#                  'length': len(s.split()),\n",
    "#                  'pol': p, 'loc':l, 'year':y, 'ocr':o,'nlp':n} \n",
    "#                      for y,p,l,o,n,t in zip(x['year'],x['pol'],x['loc'],x['ocr_quality_mean'],x['nlp'],x['text']) \n",
    "#                       for s in sent_tokenize(t)]\n",
    "            \n",
    "            \n",
    "#             }\n",
    "     \n",
    "def batched_prepare(examples, chunk_size=100):\n",
    "    sentList, polList, locList, ocrList, yearList, nlpList = [],[],[],[],[],[]\n",
    "    \n",
    "    for text, pol, loc, ocr, year, nlp in zip(examples['text'],\n",
    "                                         examples['pol'],\n",
    "                                         examples['loc'],\n",
    "                                         examples['ocr_quality_mean'],\n",
    "                                         examples['year'],\n",
    "                                         examples['nlp']):\n",
    "        text = text.split()\n",
    "        chunks = [' '.join(text[i:i+chunk_size]) for i in range(0,len(text),chunk_size)]\n",
    "        \n",
    "        sentList.extend(chunks)\n",
    "        #lengthList.extend([len(s.split()) for s in sentences])\n",
    "        polList.extend([pol]*len(chunks))\n",
    "        locList.extend([loc]*len(chunks))\n",
    "        ocrList.extend([ocr]*len(chunks))\n",
    "        yearList.extend([year]*len(chunks))\n",
    "        nlpList.extend([nlp]*len(chunks))\n",
    "        \n",
    "    return {\"sentences\": sentList, \"loc\": locList, \"pol\": polList,\n",
    "             \"ocr\": ocrList, \"year\": yearList, 'nlp': nlpList, \n",
    "           }\n",
    "\n",
    "            \n",
    "chunked_corpus = dataset_long.map(batched_prepare, \n",
    "                              batched=True, \n",
    "                              num_proc=12,\n",
    "                              remove_columns=dataset_long.column_names\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus[30002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28710db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunked_corpus),len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_corpus_flat = sent_corpus.flatten()\n",
    "# sent_corpus_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bdc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus_split = chunked_corpus.train_test_split(\n",
    "                        test_size=.1, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus_split.save_to_disk('/datadrive_2/HMD_chunked_100_context')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf8d22",
   "metadata": {},
   "source": [
    "### End of Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd8036",
   "metadata": {},
   "source": [
    "## [SKIP FOR NOW]Train a tokenizer from the pretrained version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#chunked_corpus_split = load_from_disk('/datadrive_2/HMD_chunked_200_context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_corpus_split['train'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5415185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint = \"distilbert-base-uncased\"\n",
    "# #model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "# old_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce765a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.map(lambda examples: {'lowercased':[x.lower() for x in examples['text']]}, batched=True, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_training_corpus(dataset, batch_size=10000):\n",
    "#     return (dataset['train'][i: i+batch_size]['lowercased']\n",
    "#                 for i in range(0,len(dataset['train']), batch_size)\n",
    "#            )\n",
    "\n",
    "# training_corpus = get_training_corpus(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cfcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = old_tokenizer.train_new_from_iterator(training_corpus,30522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc147d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained(\"distilbert-hmd-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5501f1b",
   "metadata": {},
   "source": [
    "## Add special tokens to tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92345f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca85351",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus_split = load_from_disk('/datadrive_2/HMD_chunked_100_context'); chunked_corpus_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_tokens = []\n",
    "for mf in ['pol','loc']:\n",
    "    added_tokens.extend(chunked_corpus_split['train'].unique(mf))\n",
    "    \n",
    "        \n",
    "added_tokens.extend([f\"[{e}]\" for e in chunked_corpus_split['train'].unique('year')])\n",
    "tokenizer.add_tokens(added_tokens, )\n",
    "\n",
    "special_tokens =['[MET]','[YEAR]','[POL]','[LOC]']\n",
    "metadata_tokens = {f'additional_special_tokens': special_tokens}\n",
    "tokenizer.add_special_tokens(metadata_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"distilbert-hmd-uncased-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1afaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d721b1",
   "metadata": {},
   "source": [
    "## Further data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = chunked_corpus_split['train'].train_test_split(test_size=.65, seed=42)\n",
    "train_val_split = train_val_split['train'].train_test_split(test_size=.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e23116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec1d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = train_val_split.map(lambda example: {'length': [len(x.split()) for x in example['sentences']]}, \n",
    "                                        batched=True, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = train_val_split.filter(lambda x: x['length'] > 50, num_proc=6); train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e55e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train_val_split['train']['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split.save_to_disk('/datadrive_2/frozen_corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991882d",
   "metadata": {},
   "source": [
    "# Change Preprocessing/Training From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91333873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = load_from_disk('/datadrive_2/frozen_corpus')\n",
    "## experimenting on very small corpus\n",
    "#train_val_split = train_val_split['test'].train_test_split(test_size=.5)\n",
    "#train_val_split = train_val_split['test'].train_test_split(test_size=.75)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-hmd-uncased-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669198ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614c9d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0776e5d28f6f432c9c5fb20fd5d32876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/873 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a99cd2185f4c0d9db5272f28ae6d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/873 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7f4dcbfda74c5c8263edde6c72beef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/873 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56f215b22e94fa6a07e8538556095eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/873 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e65ce3cbeed4c338035a2e92a85ec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/873 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b106e21a284a4ba10eb2f240f5fbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/873 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7175c8067a1f4086bb122093636bd8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/97 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5ead6dde8c4d799cb8c6adeb23b883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/97 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8876d333cf24125baf5360da03b16ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/97 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3472299f36c54d48bb0a658a12b01b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/97 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801b66b147d740daba9de28abb407e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/97 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a47bf9fe63345698edb4a0e5ba5f4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/97 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepend_year_as_special_token(examples):\n",
    "    return {'sent_context': [f'[{y}] [SEP] {s}' for y,s in zip(examples['year'],examples['sentences'])]}\n",
    "\n",
    "def prepend_pol_as_special_token(examples):\n",
    "    return {'sent_context': [f'{p} [SEP] {s}' for p,s in zip(examples['pol'],examples['sentences'])]}\n",
    "\n",
    "def prepend_year(examples):\n",
    "    return {'sent_context': [f'{y} [SEP] {s}' for y,s in zip(examples['year'],examples['sentences'])]}\n",
    "\n",
    "def no_prepend(examples):\n",
    "    return {'sent_context': [s for s in examples['sentences']]}\n",
    "\n",
    "\n",
    "training_corpus = train_val_split.map(prepend_year_as_special_token, batched=True, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1394c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'sent_context'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'sent_context'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b98390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[1854]', '[SEP]', 'e', '.', 'fusiliers', ',', 'end', '100', 'of', 'the', 'gr', '##ena', '##dier', '##s', ',', 'march', 'for', 'embark', '##a', '-', '•', 'ur', 'attack', 'on', 'copenhagen', ',', 'the', 'cape', 'of', 'good', 'hope', ',', 'on', 'beard', 'the', 'leopard', ',', 'in', 'command', 'of', 'one', 'of', 'the', 'di', '##vi', '-', 'i', '-', 'a', 'mum', '.', '171', '-', '-', '-', '-', '-', '-', '-', '-', '-', '56', 'dublin', 'and', 'belfast', 'junction', '•', '•', '.', '.', '•', '•', '•', '•', '1', ',', '-', '45', '##7', '1', ',', '41', '##4', '_', '_', '_', '_', '_', '_', '_', 'i', 'ca', ',', 'annum', '.', 'fa', '1a', '##pp', '##oint', '##ments', '.', 'ti', '##on', 'to', '-', 'morrow', '.', 'successes', 'in', 'the', 'east', 'and', 'west', 'at', 'sea', ',', 'sir', 'john', 'duck', '-', 'si', '##ons', 'of', 'that', 'fleet', '.', 'the', 'yo', '##eng', '##est', 'son', 'of', 'the', 'deceased', '64', '##si', 'dublin', 'and', 'dr', '##og', '##hed', '##a', '.', '.', '.', '.', '-', '•', '•', '•', '•', '•', '•', '•', '•', '•', '-', 'no', '2', 'company', 'of', 'the', 'royal', 'sap', '##pers', 'and', 'miners', 'worth', \"'\", 's', 'destruction', 'of', 'the', 'french', 'squadron', 'in', 'the', 'west', 'admiral', ',', 'lieutenant', '-', 'colonel']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(training_corpus['train'][1]['sent_context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e1f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d25fda227e4f808878bdaedfc4be86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042a5a9b6e3f4242a4bb01d75d789303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53f426037be433fb2b4f953bb6b609c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50506f139e24ffab83dfb17f8714289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c753ddbf47468899f472aa204b5b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe37e74f68945ec8f5ce40b22b8385e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661b60b35aac42afa93df3bff3ae1d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3688b08def409eb8189fbf867ad250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e2cd486b064de1afabbbb1d1e990f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561035a3bfd64b6eb05dd171e6f60e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb55166caf7743498dcb3a0fe03c0356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16c627517644901a6059b6b603920e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d87fa0932044cc09cedf3984f5fba68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755358303e724c4791d934e23a467775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21abce4e895451b8169605f5a77619f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1477ea5103f4372b54eaad6298b6c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9285d3c4c64fd690dc6f0fff1831c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee24a01c236145eea5a65fc77850651d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a0d4d87dcf4f96bf461fbd14d7543d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2910eda8549946f5a7fd6fa0c45a6bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ea8ac608a54c8c9f7fa378e8d0a9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ceb4d4515c4248b607736c54d97944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003cbb917d744103884d6078f358840b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae06cc3ceed4eb9b81de7eeb49d636f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sents(examples):\n",
    "    return tokenizer(examples['sent_context'],\n",
    "             truncation=True,\n",
    "             padding='max_length',\n",
    "             max_length=256,\n",
    "             return_overflowing_tokens=False)\n",
    "    \n",
    "\n",
    "tokenized_contextualized = training_corpus.map(tokenize_sents,\n",
    "                                                   batched=True,\n",
    "                                                   num_proc=12,\n",
    "                                                   remove_columns=training_corpus['train'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07e5609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] [1848] [SEP] and work from six in'the morning till six at night. it may serve to show the badstate of the trade when we state that there are seldom less than'fifty there in the morning waiting for the chance of one or moreof the men being turned off. a rumour having been circulatedthat there were several new looms to be set on on monday, jan. 10, there were upwards of a hundred workmen waiting forthe chance of getting work, and so urgent and clamorous werethey, that the superintendent had to threaten to send for thepolice before he could make them keep [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_contextualized['train'][10]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a885a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='distilbert-hmd-uncased-st', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[MET]', '[YEAR]', '[POL]', '[LOC]']})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb0aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bc2d52cea548dcac5fb1867c001412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520c034852cd4e9981f8e3c20a571244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97279a7dd5ce4bf3ab6208367523c2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cec6889293e4618bcf8133e4f0e7c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5aeeb39c634c4a81de702aaee78711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b17de79fab84591ae3ac15a03b9d761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadb9d33642c4b9e9383f2da8574d614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a7521fce8f4da488582f43c22f4a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8655dcaa71455daaa365e8f89a8f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c1e82df6874b0b81fc3edc30c09a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4c6929dd5b491280b7075a4303ef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f486f065b3784b5b96fce9529e23d307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43b83af43a94638b1053e14d875c29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a026fff5dfb4c62b09345416727047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d1d8cdafc49a79e9bb88cd6aca091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ee03f29807477985fa49d8b15e524f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f59c6279a94156a7a829f12e2209d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b82d693c504cbab0ec79c466191caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f142d50c044122a845f99860478449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14cf130228a4dec9b3e8b5b6747e80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759eee88ed304ff49f7aa959b5cf7810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29353f816c147098a947956bc1ac354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acaafd3d63d4c888df7884587bb971e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d8a91619824032b3e35cd3653dbff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenized_contextualized = tokenized_contextualized.map(\n",
    "                lambda x: {'labels': [y.copy() for y in x['input_ids']]},\n",
    "                batched=True,\n",
    "                num_proc=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3f467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #samples= [tokenized_contextualized_small[:3]]\n",
    "# samples= [tokenized_contextualized_split['train'][i] for i in range(10)]\n",
    "# batch = data_collator(samples)\n",
    "\n",
    "# for chunk in batch[\"input_ids\"]:\n",
    "#     print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3343b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_contextualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b154b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_contextualized.save_to_disk('/datadrive_2/frozen_backup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b6b65",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69d6b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_contextualized = load_from_disk('/datadrive_2/frozen_backup')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-hmd-uncased-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c245056e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_contextualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cecaf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d317b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [1850] [SEP] of unusual importance, that itaffected in a great degree the future peace of thisem - pire, and he bored it would receive from the! lousetheconsideration it deserved. sir george grey was not in the least disposedto treat with indifference the question b fore the! louse ; nor did he think the house would ho indifferentto any practical measure on the subject. — ( hear, hear. ) the bill now before the house contemplatedthe extension of the summary jurisdiction possessed bymagistrates with regard to juvenile offenders. thatwas nothing more nor less then to leave the jaw pre - cisely es it was under the juvenile offendersact, introduced by his honourable friend themember ler [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_contextualized['train'][1000]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85db35f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30604, 768)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fb965e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81789\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_contextualized[\"train\"]) // batch_size\n",
    "print(logging_steps)\n",
    "model_name = model_checkpoint.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc6978a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    dataloader_drop_last=True,\n",
    "    output_dir=f\"/datadrive_2/{model_name}-time-st-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=10000,\n",
    "    #logging_steps=2000,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc875aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_contextualized[\"train\"],\n",
    "    eval_dataset=tokenized_contextualized[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274c07a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive/anaconda3/envs/lm/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5234550\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 81789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77780' max='81789' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77780/81789 23:32:02 < 1:12:46, 0.92 it/s, Epoch 0.95/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-10000\n",
      "Configuration saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-10000/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-10000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-30000\n",
      "Configuration saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-30000/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-30000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-40000\n",
      "Configuration saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-40000/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-40000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-50000\n",
      "Configuration saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-50000/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-50000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-60000\n",
      "Configuration saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-60000/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-60000/pytorch_model.bin\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-70000\n",
      "Configuration saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-70000/config.json\n",
      "Model weights saved in /datadrive_2/distilbert-base-uncased-time-st-finetuned/checkpoint-70000/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/datadrive_2/time-st-y')\n",
    "tokenizer.save_pretrained(\"/datadrive_2/time-st-y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bcaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/datadrive_2/test')\n",
    "tokenizer.save_pretrained(\"/datadrive_2/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained(\"/datadrive_2/bnert_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = AutoModelForMaskedLM.from_pretrained('bnert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f24e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=\"/datadrive_2/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82099904",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filler(\"[CLS] [MASK] [SEP] confident it will meet with that warm and generalsupport which its just and sound policy alike demand. by thus according to the people of ireland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd469f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_contextualized['train'][200000]['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1820 [SEP] 2 [SEP] 0 [SEP] the Prime Minister is Mr. [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1820 [SEP] 3 [SEP] 0 [SEP] there is plenty of [MASK] machines.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7370f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1820 [SEP] 6 [SEP] 14 [SEP] He was involved in a [MASK] accident.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095dc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50658246",
   "metadata": {},
   "outputs": [],
   "source": [
    "'1820 6 14 he was involved in a serious accident.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade22546",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1810 [SEP] 2 [SEP] 1 [SEP] [MASK] Majesty.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[MASK] [SEP] 2 [SEP] 1 [SEP] The war between Denmark and Germany took a deadly toll.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcf55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[MASK] [SEP] 6 [SEP] 14 [SEP] The war between France and Germany took a deadly toll.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1880 [SEP] 6 [SEP] 14 [SEP] The war in [MASK] took a deadly toll.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d85819",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1880 [SEP] 2 [SEP] 14 [SEP] The revolution in [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1880 [SEP] [MASK] [SEP] 1 [SEP] liberal progress opinion liberal progress opinion liberal progress opinion.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21723d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1870 [SEP] 0 [SEP] 0 [SEP] The train is leaving in [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c88fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol2id, loc2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5505f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1830 [SEP] 0 [SEP] 1 [SEP] The train is heading towards [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence'].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1830 [SEP] 0 [SEP] [MASK] [SEP] This paper is published in Manchester.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence'].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('1830 [SEP] 0 [SEP] 1 [SEP] The train is heading towards [MASK].', return_tensors=\"pt\")\n",
    "outputs = model(**inputs.to('cuda'))\n",
    "\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b100cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = AutoModelForTokenClassification.from_pretrained('bnert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c2696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a002d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('1830 [SEP] 0 [SEP] 1 [SEP] The train is heading towards [MASK].', return_tensors=\"pt\")\n",
    "outputs = tmodel(**inputs.to('cuda'))\n",
    "\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8999da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fpipe = pipeline('feature-extraction',model='bnert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = fpipe('1880 [SEP] 0 [SEP] 1 [SEP] The train is heading towards london.')\n",
    "pen1 = features1[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989550e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = fpipe('1820 [SEP] 0 [SEP] 0 [SEP] The train is heading towards london.')\n",
    "pen2 = features2[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd493cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "cosine(pen1,pen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a2ccd",
   "metadata": {},
   "source": [
    "## To revisit later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "def masking_sentence(features):\n",
    "    #print(features)\n",
    "    for feature in features:\n",
    "        \n",
    "        input_ids = np.array(feature[\"input_ids\"])\n",
    "        no_pad = input_ids[np.where(input_ids > 0)[0]]\n",
    "        labels = np.array(feature[\"labels\"])\n",
    "        new_labels = np.array([-100]*len(no_pad))\n",
    "        mask = np.random.binomial(1, .15, (len(no_pad),))\n",
    "        mask[:7] = 0\n",
    "        idxs = np.where(mask)\n",
    "        input_ids[idxs] = tokenizer.mask_token_id\n",
    "        \n",
    "        feature['input_ids'] = input_ids\n",
    "        \n",
    "    return default_data_collator(features)\n",
    "\n",
    "\n",
    "#samples= [tokenized_contextualized_small[:3]]\n",
    "samples= [tokenized_contextualized_small[i] for i in range(10)]\n",
    "batch = masking_sentence(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm",
   "language": "python",
   "name": "lm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
