{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c47094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset,load_from_disk\n",
    "from transformers import Trainer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec61b71",
   "metadata": {},
   "source": [
    "We set a directory for caching the dataset files, otherwise the `/home` directory will overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d75097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/datadrive_2/hf_cache/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87938390",
   "metadata": {},
   "source": [
    "## Load Dataset and filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f7b9f",
   "metadata": {},
   "source": [
    "Import the datasets from the HuggingFace hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"davanstrien/hmd_newspapers\", cache_dir=cache_dir)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b505b",
   "metadata": {},
   "source": [
    "Because some files seem to lack a date, we filter first to avoid errors later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: (x['date'] is not None) \\\n",
    "                         or (x['ocr_quality_mean'] is not None), num_proc=6)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c87116",
   "metadata": {},
   "source": [
    "## Link Data\n",
    "\n",
    "In this section of the notebook we focus on further enriching an contextualizing the data by adding the political leaning as a variable. We also add the NLP identifier (used by FMP) which can be used later for adding metadata.\n",
    "\n",
    "We will map the political leaning to special tokens added to the tokenizer instance below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from NLP to political leaning\n",
    "# this is created semi-manually for this limited dataset\n",
    "nlp2pol = {2083:'neutral',\n",
    " 2084:'neutral',\n",
    " 2085:'neutral',\n",
    " 2088:'conservative',\n",
    " 2089:'conservative',\n",
    " 2090:'conservative',\n",
    " 2194:'liberal',\n",
    " 2244:'none',\n",
    " 2642:'liberal',\n",
    " 2643:'conservative', # not found\n",
    " 2644:'conservative',\n",
    " 2645:'conservative',\n",
    " 2646:'none', # https://en.wikipedia.org/wiki/The_Star_(1788)\n",
    " 2647:'radical', # https://www.britishnewspaperarchive.co.uk/titles/statesman-london\n",
    "}\n",
    "\n",
    "pol2code = {'none':'[none]','neutral':'[neutr]','conservative':'[con]','liberal':'[lib]','radical':'[rad]'}\n",
    "\n",
    "loc2code = {'Liverpool, Merseyside, England':'[liverpool]', 'London, England':'[london]'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a52f58c",
   "metadata": {},
   "source": [
    "Because the original data lacks an NLP identifier for now, we add it via the title. For this we first need to create a mapping between NLP and titles for each publication year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "nlp_dict = defaultdict(dict)\n",
    "url = 'https://raw.githubusercontent.com/Living-with-machines/hmd_url_generator/main/HMD_title_urls.json'\n",
    "data = requests.get(url).json()\n",
    "for newspaper, year_dict in data.items():\n",
    "    for year, info_dict in year_dict.items():\n",
    "        if info_dict['fname'].endswith('zip'):\n",
    "            nlp_dict[newspaper][int(year)] = int(info_dict['fname'].split('_')[1])\n",
    "nlp_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4eb046",
   "metadata": {},
   "source": [
    "To match the titles between the `dataset` and the `nlp_dict` we need just one more dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtitle2title = {'The Northern Daily Times.':'The Northern Daily Times etc',\n",
    " 'Northern Times.':'The Northern Daily Times etc',\n",
    " 'The Daily Times.':'The Northern Daily Times etc',\n",
    " 'The Liverpool Standard and General Commercial Advertiser.':'The Liverpool Standard etc',\n",
    " 'The Liverpool Standard, and General Advertiser.':'The Liverpool Standard etc',\n",
    " 'The Sun.':'The Sun',\n",
    " 'Colored News.':'Colored News',\n",
    " 'The Express.':'The Express',\n",
    " 'The National Register.':'National Register.',\n",
    " 'The Press.':'The Press.',\n",
    " 'Star.':'The Star',\n",
    " 'The Statesman.':'The Statesman'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02c2dd",
   "metadata": {},
   "source": [
    "## Prepare Chunked Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a57c1c",
   "metadata": {},
   "source": [
    "The code below extends information on each article by\n",
    "- splitting the date into year and month\n",
    "- add an NLP identifier as well codes for location and political leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cols(example):\n",
    "\n",
    "    nlp = nlp_dict[dtitle2title[example['title']]][example['date'].year]\n",
    "    \n",
    "    return {'year': example['date'].year,\n",
    "            'length': len(example['text'].split()),\n",
    "            'month': example['date'].month,\n",
    "            'nlp' : nlp,\n",
    "            'pol': pol2code[nlp2pol[nlp]],\n",
    "            'loc': loc2code[example['location']]\n",
    "           }\n",
    "\n",
    "\n",
    "dataset = dataset.map(add_cols , num_proc=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03556a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk('/datadrive_2/HMD_context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53147bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.Series(dataset['train']['length'])\n",
    "lengths.plot(kind='hist',bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b08bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lengths > 100) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49605e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_long = dataset.filter(lambda x: x['length'] >= 100, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['train']),len(dataset_long['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19175da3",
   "metadata": {},
   "source": [
    "After replacing the columns with codes we can remove some information from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_long = dataset_long['train'].remove_columns(['title', 'location', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_small = dataset.shuffle(seed=0).select(range(100_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8259f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include_cols = []\n",
    "\n",
    "# def sent_split(x):\n",
    "#      return {'data': [\n",
    "#                 {'sentence':s.lower(),\n",
    "#                  'length': len(s.split()),\n",
    "#                  'pol': p, 'loc':l, 'year':y, 'ocr':o,'nlp':n} \n",
    "#                      for y,p,l,o,n,t in zip(x['year'],x['pol'],x['loc'],x['ocr_quality_mean'],x['nlp'],x['text']) \n",
    "#                       for s in sent_tokenize(t)]\n",
    "            \n",
    "            \n",
    "#             }\n",
    "     \n",
    "def batched_prepare(examples, chunk_size=100):\n",
    "    sentList, polList, locList, ocrList, yearList, nlpList = [],[],[],[],[],[]\n",
    "    \n",
    "    for text, pol, loc, ocr, year, nlp in zip(examples['text'],\n",
    "                                         examples['pol'],\n",
    "                                         examples['loc'],\n",
    "                                         examples['ocr_quality_mean'],\n",
    "                                         examples['year'],\n",
    "                                         examples['nlp']):\n",
    "        text = text.split()\n",
    "        chunks = [' '.join(text[i:i+chunk_size]) for i in range(0,len(text),chunk_size)]\n",
    "        \n",
    "        sentList.extend(chunks)\n",
    "        #lengthList.extend([len(s.split()) for s in sentences])\n",
    "        polList.extend([pol]*len(chunks))\n",
    "        locList.extend([loc]*len(chunks))\n",
    "        ocrList.extend([ocr]*len(chunks))\n",
    "        yearList.extend([year]*len(chunks))\n",
    "        nlpList.extend([nlp]*len(chunks))\n",
    "        \n",
    "    return {\"sentences\": sentList, \"loc\": locList, \"pol\": polList,\n",
    "             \"ocr\": ocrList, \"year\": yearList, 'nlp': nlpList, \n",
    "           }\n",
    "\n",
    "            \n",
    "chunked_corpus = dataset_long.map(batched_prepare, \n",
    "                              batched=True, \n",
    "                              num_proc=12,\n",
    "                              remove_columns=dataset_long.column_names\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus[30002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d96edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunked_corpus),len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_corpus_flat = sent_corpus.flatten()\n",
    "# sent_corpus_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus_split = chunked_corpus.train_test_split(\n",
    "                        test_size=.1, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_corpus_split.save_to_disk('/datadrive_2/HMD_chunked_100_context')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0414cb0",
   "metadata": {},
   "source": [
    "### End of Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e0be7",
   "metadata": {},
   "source": [
    "## Add special tokens to tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d32e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a3ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "        num_rows: 17408478\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "        num_rows: 1934276\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_corpus_split = load_from_disk('/datadrive_2/HMD_chunked_100_context'); chunked_corpus_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5587027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #special year tokens\n",
    "# added_tokens = []\n",
    "# for mf in ['pol','loc']:\n",
    "#     added_tokens.extend(chunked_corpus_split['train'].unique(mf))\n",
    "    \n",
    "        \n",
    "# added_tokens.extend([f\"[{e}]\" for e in chunked_corpus_split['train'].unique('year')])\n",
    "# tokenizer.add_tokens(added_tokens, )\n",
    "\n",
    "# special_tokens =['[MET]','[DATE]','[POL]','[LOC]']\n",
    "# metadata_tokens = {f'additional_special_tokens': special_tokens}\n",
    "# tokenizer.add_special_tokens(metadata_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4adc91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no special year tokens\n",
    "special_tokens =['[DATE]']\n",
    "metadata_tokens = {f'additional_special_tokens': special_tokens}\n",
    "tokenizer.add_special_tokens(metadata_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65ed7a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distilbert-hmd-uncased-no-st/tokenizer_config.json',\n",
       " 'distilbert-hmd-uncased-no-st/special_tokens_map.json',\n",
       " 'distilbert-hmd-uncased-no-st/vocab.txt',\n",
       " 'distilbert-hmd-uncased-no-st/added_tokens.json',\n",
       " 'distilbert-hmd-uncased-no-st/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"distilbert-hmd-uncased-no-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faf8433b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "        num_rows: 17408478\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "        num_rows: 1934276\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_corpus_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6616c1c",
   "metadata": {},
   "source": [
    "## Further data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebdbc844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /datadrive_2/HMD_chunked_100_context/train/cache-9b67b89688c1829e.arrow and /datadrive_2/HMD_chunked_100_context/train/cache-7fc302acfd653d0b.arrow\n",
      "Loading cached split indices for dataset at /datadrive_2/HMD_chunked_100_context/train/cache-d4bca848d4a65ab1.arrow and /datadrive_2/HMD_chunked_100_context/train/cache-64d0bcc15f135261.arrow\n"
     ]
    }
   ],
   "source": [
    "train_val_split = chunked_corpus_split['train'].train_test_split(test_size=.65, seed=42)\n",
    "train_val_split = train_val_split['train'].train_test_split(test_size=.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a80fbf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "        num_rows: 5483670\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr'],\n",
       "        num_rows: 609297\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fa346cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-dbe333742a4436b5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-1d23bbeb46aa9dcb.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-ec25fd3545064c60.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-4fe4cf3976f4a163.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e35fcc4dd77a77e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-ea065d33e601b0d8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-b176b06073f6b01e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-0af3473ae79db449.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-2fc1ab65227b79cd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-86ffe4579f62550f.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-6aad2840f7a0cbb1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-8f6e88883b59bf2f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-a35803e6f67bf76a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-bbae4a14f9e6761d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-50adb7b511dedceb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-2f5417d59a4dc6dc.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-590be86e91357182.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-8cb84bf5a7b02179.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-6963340f9a6261a4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-d49b1be036a02de0.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-fda199c8dfa76b4f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-896e45d57b16d04a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-ca696bbc5f595125.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-f5e86e79d739900d.arrow\n"
     ]
    }
   ],
   "source": [
    "train_val_split = train_val_split.map(lambda example: {'length': [len(x.split()) for x in example['sentences']]}, \n",
    "                                        batched=True, num_proc=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cc47cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e086fefa5ba7cb5_00000_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e086fefa5ba7cb5_00001_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e086fefa5ba7cb5_00002_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e086fefa5ba7cb5_00003_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e086fefa5ba7cb5_00004_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-3e086fefa5ba7cb5_00005_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-c2114242ad715b46_00000_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-c2114242ad715b46_00001_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-c2114242ad715b46_00002_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-c2114242ad715b46_00003_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-c2114242ad715b46_00004_of_00006.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-c2114242ad715b46_00005_of_00006.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split = train_val_split.filter(lambda x: x['length'] > 50, num_proc=6); train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c482c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517948141"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_val_split['train']['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c19fbf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-a8db6d15a7ede0a8.arrow\n",
      "Loading cached processed dataset at /datadrive_2/HMD_chunked_100_context/train/cache-2f89a525a7b8ec7d.arrow\n"
     ]
    }
   ],
   "source": [
    "train_val_split.save_to_disk('/datadrive_2/frozen_corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479aa661",
   "metadata": {},
   "source": [
    "# Change Preprocessing/Training From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b1f721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = load_from_disk('/datadrive_2/frozen_corpus')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-hmd-uncased-no-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f97430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30523"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbab6893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "888e77d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-8fbe391d98ed3603.arrow\n",
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-2c17f8836366e29f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-31dcfc93b2005630.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-b99bbfd3c2e53573.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-72ae37e3ef526888.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/train/cache-e0988e21156ac8bd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-58f5734859d57710.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-083535b7b3844aaa.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-809e136b42abcd13.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-e0d3f637a8a92928.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-8e14aec9b2902488.arrow\n",
      "Loading cached processed dataset at /datadrive_2/frozen_corpus/test/cache-f64f066520513653.arrow\n"
     ]
    }
   ],
   "source": [
    "def prepend_year_as_special_token(examples):\n",
    "    return {'sent_context': [f'[{y}] [SEP] {s}' for y,s in zip(examples['year'],examples['sentences'])]}\n",
    "\n",
    "#def prepend_pol_as_special_token(examples):\n",
    "#    return {'sent_context': [f'{p} [SEP] {s}' for p,s in zip(examples['pol'],examples['sentences'])]}\n",
    "\n",
    "def prepend_year(examples):\n",
    "    return {'sent_context': [f'{y} [DATE] {s}' for y,s in zip(examples['year'],examples['sentences'])]}\n",
    "\n",
    "def no_prepend(examples):\n",
    "    return {'sent_context': [s for s in examples['sentences']]}\n",
    "\n",
    "\n",
    "training_corpus = train_val_split.map(prepend_year, batched=True, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9158c45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'sent_context'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['year', 'nlp', 'pol', 'loc', 'sentences', 'ocr', 'length', 'sent_context'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28c93c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1854', '[DATE]', 'e', '.', 'fusiliers', ',', 'end', '100', 'of', 'the', 'gr', '##ena', '##dier', '##s', ',', 'march', 'for', 'embark', '##a', '-', '•', 'ur', 'attack', 'on', 'copenhagen', ',', 'the', 'cape', 'of', 'good', 'hope', ',', 'on', 'beard', 'the', 'leopard', ',', 'in', 'command', 'of', 'one', 'of', 'the', 'di', '##vi', '-', 'i', '-', 'a', 'mum', '.', '171', '-', '-', '-', '-', '-', '-', '-', '-', '-', '56', 'dublin', 'and', 'belfast', 'junction', '•', '•', '.', '.', '•', '•', '•', '•', '1', ',', '-', '45', '##7', '1', ',', '41', '##4', '_', '_', '_', '_', '_', '_', '_', 'i', 'ca', ',', 'annum', '.', 'fa', '1a', '##pp', '##oint', '##ments', '.', 'ti', '##on', 'to', '-', 'morrow', '.', 'successes', 'in', 'the', 'east', 'and', 'west', 'at', 'sea', ',', 'sir', 'john', 'duck', '-', 'si', '##ons', 'of', 'that', 'fleet', '.', 'the', 'yo', '##eng', '##est', 'son', 'of', 'the', 'deceased', '64', '##si', 'dublin', 'and', 'dr', '##og', '##hed', '##a', '.', '.', '.', '.', '-', '•', '•', '•', '•', '•', '•', '•', '•', '•', '-', 'no', '2', 'company', 'of', 'the', 'royal', 'sap', '##pers', 'and', 'miners', 'worth', \"'\", 's', 'destruction', 'of', 'the', 'french', 'squadron', 'in', 'the', 'west', 'admiral', ',', 'lieutenant', '-', 'colonel']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(training_corpus['train'][1]['sent_context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ae9bc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2417cd9397646c5a06fe669dfb7d53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cc388cfb874c65b4f9c1eba22ec2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aa87af08da435ca8746c6aa5e732af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef6835374aa4c308876e15ab6e0e102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43efc7e6084a4faf8fcdfa8c79fc61e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d539d9b240b47b3a85b5f0f67e62b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2a786f005745f9ad7197b39913fefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f5506778eb43c091a993af3242a755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b767a741e8574ed284897d6a207bc858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94392e9cdd8f4a1f93f8e6ccf32592c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3514aec7ee5b4bd6a3c8bb9706366ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1ee7a9302c4b96a8fcce5a9cbdc578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda50c55a2214d758d932da0b9efe8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3da7adfacd7412b8d073154f97ecf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee1b9ec50924d49802c2d12e37478ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15383436be044b4c9bca44dc3d680971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6f14eb8ad4b04a7878003abc85165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3526ed65ec2943eb9b253cafa7e0a9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2297f977b284694a4af01adeb76d0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28274f4873384f4e9120d1a9334ed5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68177fa2ef874665bd0f257796522f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562b59f6aba4444988b14378baf56a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d37917babd5426785d9323cea878a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bcaf07a3af411dba72cbb8bde31184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sents(examples):\n",
    "    return tokenizer(examples['sent_context'],\n",
    "             truncation=True,\n",
    "             padding='max_length',\n",
    "             max_length=256,\n",
    "             return_overflowing_tokens=False)\n",
    "    \n",
    "\n",
    "tokenized_contextualized = training_corpus.map(tokenize_sents,\n",
    "                                                   batched=True,\n",
    "                                                   num_proc=12,\n",
    "                                                   remove_columns=training_corpus['train'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dcc3e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] 1848 [DATE] and work from six in'the morning till six at night. it may serve to show the badstate of the trade when we state that there are seldom less than'fifty there in the morning waiting for the chance of one or moreof the men being turned off. a rumour having been circulatedthat there were several new looms to be set on on monday, jan. 10, there were upwards of a hundred workmen waiting forthe chance of getting work, and so urgent and clamorous werethey, that the superintendent had to threaten to send for thepolice before he could make them keep [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_contextualized['train'][10]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1931267f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='distilbert-hmd-uncased-no-st', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[DATE]']})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "729dd734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92f8cb6c5bb4c13adeb9e072fbd87e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94a1e733a8e4ec2b5c3fbcf2945723e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1cd12f35bf4e3f8eda06f051278d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba0390d2cc048abb3dd603702583460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230831d1d81c4126b1da8922d3704569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315320299aa7453c86966d0bfb72b266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbefa5e8749b40eb87fb875ea681b4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b41a9c070ea4fc0902959dcd34e8e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491633cd345640b280b9f935d9ce3d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702f8713200d4aaf8db3dc72cc9622ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771758a926874319b37aba5482abf9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2f6d9ec41942d0b254d138a1a4e378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/437 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97354873ee044a97963acdeb5abc3654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cadbc8117843ea8c17ab75be7e5080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c28fac05674e47ab61f28ae4dcce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607ee2f8883c4f668485e6ec534afe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab66e1af1bb41cc84d4423b9183b3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a503697cfa4eb69620de0609f8cad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9906e1f19bc245cbb7219d10f6c5a89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131253b4c1594a13adba46e2016a7658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf63220561f4696a0d30bac2c24a146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5830a0b5c0cc454c8fd3fc859447cece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b2ead7c4d43a78d4ab8835c80af86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6648ca0a552140148bdc1d6d5d343247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/49 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenized_contextualized = tokenized_contextualized.map(\n",
    "                lambda x: {'labels': [y.copy() for y in x['input_ids']]},\n",
    "                batched=True,\n",
    "                num_proc=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68572015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_contextualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2b067a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_contextualized.save_to_disk('/datadrive_2/frozen_backup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4456b7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca73546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_contextualized = load_from_disk('/datadrive_2/frozen_backup')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-hmd-uncased-no-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7516f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5234550\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 581857\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_contextualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5a37fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d71fddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 1850 [DATE] of unusual importance, that itaffected in a great degree the future peace of thisem - pire, and he bored it would receive from the! lousetheconsideration it deserved. sir george grey was not in the least disposedto treat with indifference the question b fore the! louse ; nor did he think the house would ho indifferentto any practical measure on the subject. — ( hear, hear. ) the bill now before the house contemplatedthe extension of the summary jurisdiction possessed bymagistrates with regard to juvenile offenders. thatwas nothing more nor less then to leave the jaw pre - cisely es it was under the juvenile offendersact, introduced by his honourable friend themember ler [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_contextualized['train'][1000]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94235697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30523, 768)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12d5c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81789\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_contextualized[\"train\"]) // batch_size\n",
    "print(logging_steps)\n",
    "model_name = model_checkpoint.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "709c656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    dataloader_drop_last=True,\n",
    "    output_dir=f\"/datadrive_2/{model_name}-time-st-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=10000,\n",
    "    #logging_steps=2000,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bb13ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_contextualized[\"train\"],\n",
    "    eval_dataset=tokenized_contextualized[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c4873",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datadrive/anaconda3/envs/lm/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5234550\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 81789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='81789' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  170/81789 03:03 < 24:48:06, 0.91 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82dd719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/datadrive_2/bnert-time-y')\n",
    "tokenizer.save_pretrained(\"/datadrive_2/bnert-time-y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc1eea",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b682600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #samples= [tokenized_contextualized_small[:3]]\n",
    "# samples= [tokenized_contextualized_split['train'][i] for i in range(10)]\n",
    "# batch = data_collator(samples)\n",
    "\n",
    "# for chunk in batch[\"input_ids\"]:\n",
    "#     print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012163e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/datadrive_2/bnert-time-y-backup')\n",
    "tokenizer.save_pretrained(\"/datadrive_2/bnert-time-y-backup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33546a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained(\"/datadrive_2/bnert_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbff9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = AutoModelForMaskedLM.from_pretrained('bnert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ed7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=\"/datadrive_2/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filler(\"[CLS] [MASK] [SEP] confident it will meet with that warm and generalsupport which its just and sound policy alike demand. by thus according to the people of ireland\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_contextualized['train'][200000]['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1820 [SEP] 2 [SEP] 0 [SEP] the Prime Minister is Mr. [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1820 [SEP] 3 [SEP] 0 [SEP] there is plenty of [MASK] machines.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81228aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1820 [SEP] 6 [SEP] 14 [SEP] He was involved in a [MASK] accident.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd291cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "'1820 6 14 he was involved in a serious accident.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1810 [SEP] 2 [SEP] 1 [SEP] [MASK] Majesty.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[MASK] [SEP] 2 [SEP] 1 [SEP] The war between Denmark and Germany took a deadly toll.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[MASK] [SEP] 6 [SEP] 14 [SEP] The war between France and Germany took a deadly toll.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1880 [SEP] 6 [SEP] 14 [SEP] The war in [MASK] took a deadly toll.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1880 [SEP] 2 [SEP] 14 [SEP] The revolution in [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf924fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1880 [SEP] [MASK] [SEP] 1 [SEP] liberal progress opinion liberal progress opinion liberal progress opinion.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea48a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1870 [SEP] 0 [SEP] 0 [SEP] The train is leaving in [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol2id, loc2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1830 [SEP] 0 [SEP] 1 [SEP] The train is heading towards [MASK].'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence'].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d482a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1830 [SEP] 0 [SEP] [MASK] [SEP] This paper is published in Manchester.'\n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence'].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('1830 [SEP] 0 [SEP] 1 [SEP] The train is heading towards [MASK].', return_tensors=\"pt\")\n",
    "outputs = model(**inputs.to('cuda'))\n",
    "\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a333d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = AutoModelForTokenClassification.from_pretrained('bnert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('1830 [SEP] 0 [SEP] 1 [SEP] The train is heading towards [MASK].', return_tensors=\"pt\")\n",
    "outputs = tmodel(**inputs.to('cuda'))\n",
    "\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fpipe = pipeline('feature-extraction',model='bnert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe45119",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = fpipe('1880 [SEP] 0 [SEP] 1 [SEP] The train is heading towards london.')\n",
    "pen1 = features1[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a460583",
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = fpipe('1820 [SEP] 0 [SEP] 0 [SEP] The train is heading towards london.')\n",
    "pen2 = features2[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "cosine(pen1,pen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb4cdd",
   "metadata": {},
   "source": [
    "## To revisit later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd63bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "def masking_sentence(features):\n",
    "    #print(features)\n",
    "    for feature in features:\n",
    "        \n",
    "        input_ids = np.array(feature[\"input_ids\"])\n",
    "        no_pad = input_ids[np.where(input_ids > 0)[0]]\n",
    "        labels = np.array(feature[\"labels\"])\n",
    "        new_labels = np.array([-100]*len(no_pad))\n",
    "        mask = np.random.binomial(1, .15, (len(no_pad),))\n",
    "        mask[:7] = 0\n",
    "        idxs = np.where(mask)\n",
    "        input_ids[idxs] = tokenizer.mask_token_id\n",
    "        \n",
    "        feature['input_ids'] = input_ids\n",
    "        \n",
    "    return default_data_collator(features)\n",
    "\n",
    "\n",
    "#samples= [tokenized_contextualized_small[:3]]\n",
    "samples= [tokenized_contextualized_small[i] for i in range(10)]\n",
    "batch = masking_sentence(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm",
   "language": "python",
   "name": "lm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
